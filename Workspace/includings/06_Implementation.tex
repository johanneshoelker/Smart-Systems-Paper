\section{Proof of Concept}\label{implementation}
The best fitting strategies extracted in \autoref{application} are implemented on a small test data set in order to demonstrate how and if they work. First the used dataset ant the purpose of AD for the specific use case is described. Later the process of implemention and the results are presented.
\subsection{Inverter data including Anomalies}
While NLP and image processing tasks are common and a variety of data sets exists, time series data sets are not available that much \cite{ma_survey_2023}. Thanks to the employees of SMA a multivariate time series dataset is provided. The specific use case and the structure of the chosen data is described in this section.

% Use case for sma
SMA developes and manufactures inverters for home and commercial use. The inverters convert direct to alternating current or vice versa depending on the use case. They also act as home managers controlling all energy flows in a power plant. Inverters are equipped with several sensors measuring the surroundings and internal states in order to maximize the efficency and to avoid system failures. Sometimes system failures appear still which raises the question if this could have been foreseen by analyzing the gathered sensor data during runtime. The first step to reach such a forecasting tool is to detect the anomalies in recorded sensor data. The implementation of the chosen methods is therefore done on inverter data provided by the company.

% Features in data
The variables contain measurements of current and voltage of all phases in AC and the generated DC sources. Additionally temperatures, CPU usage, internal parameter settings and many other measurements are included. The total number of features is 137.

% Data structure
The values are collectively stored at a 7 minute interval over several months. 19 inverters that had system failures at some point are taken into account. These failure time stamps are known and added as an additional feature with a binary value of 1. Every other error bit is 0. The data is collected between 2018 and 2020 and the locations of the inverters cannot be provided.

% TODO DEfiniton of training and test data
% In the test data the learning data is seperate from the data including anomalies. The important thing about Zero Shot Learning is that a specific anomaly never occured like this before. In the test data, all chosen representation learning techniques are applied using the same data for learning and afterwards testing the AD with the same anomalies. According to chapter (Evaluation) the characteristics are evaluated for each RL technique chosen in the previous chapter.

\subsection{Implemented Methods}
The main goal is to detect the labeled anomalies in the SMA dataset. If the methods find the timestamp of the system failure, they perform correctly. First the models are taken as is and a forward pass is applied. The given output is evaluated if the model already detects the failure time points in the inverter time series data. If possible, the model is trained afterwards using a set of 12 inverters and tested on the remaining 7 inverters. This way the Zero-Shot scenario like in \autoref{theory} is created.
The code for the implementions can be found on link \footnote{\fussy\tiny github.com/johanneshoelker/Smart-Systems-Paper/tree/main/Implementation \label{foot_impl}}.

% TS2Vec
\subsubsection{TS2Vec}
An implemention of the model TS2Vec is done by the authors using Python which is available in \autoref{foot_ts2vec}. A function for preprocessing the data to fit as an input for the model is available in \autoref{foot_impl}.
Using the function a successful forward pass was made. The learned representations can be used for further evaluation.

% MEGA
\subsubsection{MEGA}
According to \cite{wang_multiscale_2023} the model MEGA is trained and evaluated on three different datasets. The code for reproduction is provided by the authors. They implement the model using Python on \autoref{foot_mega}. No further information on how to adapt the model on new datasets is given but the scripts are adapted to run successfully with SMA data as multivariate input. The output was not further reviewed.

\subsubsection{DAEMON}
The authors of the method DAEMON published python scripts for replicating the results on all datasets they used \cite{chen_adversarial_2023}. However, no explanation on how to use the method for entirely new datasets can be found on this \autoref{foot_daemon}.

% Moment
\subsubsection{MOMENT}
A detailed instruction on how to reproduce the outcomes of MOMENT presented by \cite{goswami_moment_2024} is provided on this GitHub \autoref{foot_moment}. The method takes a three dimensional input tensor, containing batches, channels and time points. The maximal number of points is 512. It reconstructs the given input and returns a tensor containing the reconstructions.

For the implementation on SMA data the provided tutorial is used as a guide. The SMA data is preprocessed to match the requested input tensor. The reconstructions are further compared with the inputs by calulating the Mean Squared Error (MSE):
\begin{equation}
    \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2
\end{equation}
The error is further normalized using the Min-Max Normalization:
\begin{equation}
x' = \frac{x - \text{min}(x)}{\text{max}(x) - \text{min}(x)}
\end{equation}
Every timestamp that exceeds a certain threshold then represents the found anomalies.

% Results
One sensor needed to be excluded because the values didn't change. The threshold was decreased until 0.005 but with an untrained model no anomalies are found.
