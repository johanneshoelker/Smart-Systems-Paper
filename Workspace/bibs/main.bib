
@misc{dau_ucr_2019,
	title = {The {UCR} {Time} {Series} {Archive}},
	url = {http://arxiv.org/abs/1810.07758},
	abstract = {The UCR Time Series Archive - introduced in 2002, has become an important resource in the time series data mining community, with at least one thousand published papers making use of at least one data set from the archive. The original incarnation of the archive had sixteen data sets but since that time, it has gone through periodic expansions. The last expansion took place in the summer of 2015 when the archive grew from 45 to 85 data sets. This paper introduces and will focus on the new data expansion from 85 to 128 data sets. Beyond expanding this valuable resource, this paper offers pragmatic advice to anyone who may wish to evaluate a new algorithm on the archive. Finally, this paper makes a novel and yet actionable claim: of the hundreds of papers that show an improvement over the standard baseline (1-nearest neighbor classiﬁcation), a large fraction may be mis-attributing the reasons for their improvement. Moreover, they may have been able to achieve the same improvement with a much simpler modiﬁcation, requiring just a single line of code.},
	language = {en},
	urldate = {2024-08-23},
	publisher = {arXiv},
	author = {Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
	month = sep,
	year = {2019},
	note = {arXiv:1810.07758 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{kravchik_detecting_2018,
	title = {Detecting {Cyberattacks} in {Industrial} {Control} {Systems} {Using} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1806.08110},
	abstract = {This paper presents a study on detecting cyberattacks on industrial control systems (ICS) using unsupervised deep neural networks, specifically, convolutional neural networks. The study was performed on a Secure Water Treatment testbed (SWaT) dataset, which represents a scaled-down version of a real-world industrial water treatment plant. e suggest a method for anomaly detection based on measuring the statistical deviation of the predicted value from the observed value. We applied the proposed method by using a variety of deep neural networks architectures including different variants of convolutional and recurrent networks. The test dataset from SWaT included 36 different cyberattacks. The proposed method successfully detects the vast majority of the attacks with a low false positive rate thus improving on previous works based on this data set. The results of the study show that 1D convolutional networks can be successfully applied to anomaly detection in industrial control systems and outperform more complex recurrent networks while being much smaller and faster to train.},
	language = {en},
	urldate = {2024-08-21},
	publisher = {arXiv},
	author = {Kravchik, Moshe and Shabtai, Asaf},
	month = dec,
	year = {2018},
	note = {arXiv:1806.08110 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{sabokrou_deep-anomaly__2018,
	title = {Deep-anomaly\_ {Fully} convolutional neural network for fast anomaly detection in crowded scenes},
	abstract = {The detection of abnormal behaviour in crowded scenes has to deal with many challenges. This paper presents an eﬃcient method for detection and localization of anomalies in videos. Using fully convolutional neural networks (FCNs) and temporal data, a pre-trained supervised FCN is transferred into an unsupervised FCN ensuring the detection of (global) anomalies in scenes. High performance in terms of speed and accuracy is achieved by investigating the cascaded detection as a result of reducing computation complexities. This FCN-based architecture addresses two main tasks, feature representation and cascaded outlier detection. Experimental results on two benchmarks suggest that the proposed method outperforms existing methods in terms of accuracy regarding detection and localization.},
	language = {en},
	journal = {Computer Vision and Image Understanding},
	author = {Sabokrou, Mohammad},
	year = {2018},
}

@article{abdulaal_practical_2021,
	title = {Practical {Approach} to {Asynchronous} {Multivariate} {Time} {Series} {Anomaly} {Detection} and {Localization}},
	abstract = {Engineers at eBay utilize robust methods in monitoring IT system signals for anomalies. However, the growing scale of signals, both in volumes and dimensions, overpowers traditional statistical state-space or supervised learning tools. Thus, state-of-the-art methods based on unsupervised deep learning are sought in recent research. However, we experienced flaws when implementing those methods, such as requiring partial supervision and weaknesses to high dimensional datasets, among other reasons discussed in this paper. We propose a practical approach for inferring anomalies from large multivariate sets. We observe an abundance of time series in real-world applications, which exhibit asynchronous and consistent repetitive variations, such as IT, weather, utility, and transportation. Our solution is designed to leverage this behavior. The solution utilizes spectral analysis on the latent representation of a pre-trained autoencoder to extract dominant frequencies across the signals, which are then used in a subsequent network that learns the phase shifts across the signals and produces a synchronized representation of the raw multivariate. Random subsets of the synchronous multivariate are then fed into an array of autoencoders learning to minimize the quantile reconstruction losses, which are then used to infer and localize anomalies based on a majority vote. We benchmark this method against state-of-the-art approaches on public datasets and eBay’s data using their referenced evaluation methods. Furthermore, we address the limitations of the referenced evaluation methods and propose a more realistic evaluation method.},
	language = {en},
	author = {Abdulaal, Ahmed},
	year = {2021},
}

@misc{tuli_tranad_2022,
	title = {{TranAD}: {Deep} {Transformer} {Networks} for {Anomaly} {Detection} in {Multivariate} {Time} {Series} {Data}},
	shorttitle = {{TranAD}},
	url = {http://arxiv.org/abs/2201.07284},
	abstract = {Efficient anomaly detection and diagnosis in multivariate timeseries data is of great importance for modern industrial applications. However, building a system that is able to quickly and accurately pinpoint anomalous observations is a challenging problem. This is due to the lack of anomaly labels, high data volatility and the demands of ultra-low inference times in modern applications. Despite the recent developments of deep learning approaches for anomaly detection, only a few of them can address all of these challenges. In this paper, we propose TranAD, a deep transformer network based anomaly detection and diagnosis model which uses attentionbased sequence encoders to swiftly perform inference with the knowledge of the broader temporal trends in the data. TranAD uses focus score-based self-conditioning to enable robust multi-modal feature extraction and adversarial training to gain stability. Additionally, model-agnostic meta learning (MAML) allows us to train the model using limited data. Extensive empirical studies on six publicly available datasets demonstrate that TranAD can outperform state-of-the-art baseline methods in detection and diagnosis performance with data and time-efficient training. Specifically, TranAD increases F1 scores by up to 17\%, reducing training times by up to 99\% compared to the baselines.},
	language = {en},
	urldate = {2024-08-21},
	publisher = {arXiv},
	author = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
	month = may,
	year = {2022},
	note = {arXiv:2201.07284 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{he_temporal_2019,
	title = {Temporal {Convolutional} {Networks} for {Anomaly} {Detection} in {Time} {Series}},
	abstract = {Convolutional Networks have been demonstrated to be particularly useful for extracting high level feature in structural data. Temporal convolutional network (TCN) is a framework which employs casual convolutions and dilations so that it is adaptive for sequential data with its temporality and large receptive fields. In this paper, we apply TCN for anomaly detection in time series. We train the TCN on normal sequences and use it to predict trend in a number of time steps. Prediction errors are fitted by a multivariate Gaussian distribution and used to calculate the anomaly scores of points. In addition, a multi-scale feature mixture method is raised to promote performance. The validity of this method is confirmed on three real-world datasets.},
	language = {en},
	journal = {Journal of Physics},
	author = {He, Yangdong and Zhao, Jiabao},
	year = {2019},
}

@article{ye_multivariate_2023,
	title = {Multivariate {Time} {Series} {Anomaly} {Detection} with {Fourier} {Time} {Series} {Transformer}},
	abstract = {Anomaly detection in time series data plays a key role in automatic industrial operations. Due to the intricate temporal dependencies within time series data and the difficulty in obtaining labeled data, recent anomaly detection methods have primarily focused on the temporal domain features of time series data, neglecting the frequency domain features. However, spectral analysis can better utilize periodic information within time series data such as seasonal patterns, which helps capturing multiscale and multiple frequency features. In this paper, we present a Fourier Time Series Transformer model (FTST for short), which combines the features of both time and frequency domains for time series anomaly detection. Specifically, the attention mechanism is utilized for modeling the temporal domain, while the Fourier Transform is employed to transform time series data into frequency domain data. The frequency domain features are then modeled using a Temporal Convolutional Network. By making full use of the temporal and frequency domains of time series data, FTST can significantly enhance the performance of time series anomaly detection. Experimental results on popular benchmark datasets demonstrate the anomaly detection performance of the proposed method.},
	language = {en},
	author = {Ye, Yufeng and He, Qichao and Zhang, Peng and Xiao, Jie and Li, Zhao},
	year = {2023},
}

@article{kitchenham_systematic_2009,
	title = {Systematic literature reviews in software engineering – {A} systematic literature review},
	volume = {51},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09505849},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584908001390},
	doi = {10.1016/j.infsof.2008.09.009},
	abstract = {Background: In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference. Aims: This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence.
Method: We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings.
Results: Of 20 relevant studies, eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4.
Conclusions: Currently, the topic areas covered by SLRs are limited. European researchers, particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence and making it available to practitioners.},
	language = {en},
	number = {1},
	urldate = {2024-08-19},
	journal = {Information and Software Technology},
	author = {Kitchenham, Barbara and Pearl Brereton, O. and Budgen, David and Turner, Mark and Bailey, John and Linkman, Stephen},
	month = jan,
	year = {2009},
	pages = {7--15},
}

@misc{su_large_2024,
	title = {Large {Language} {Models} for {Forecasting} and {Anomaly} {Detection}: {A} {Systematic} {Literature} {Review}},
	shorttitle = {Large {Language} {Models} for {Forecasting} and {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2402.10350},
	abstract = {This systematic literature review comprehensively examines the application of Large Language Models (LLMs) in forecasting and anomaly detection, highlighting the current state of research, inherent challenges, and prospective future directions. LLMs have demonstrated significant potential in parsing and analyzing extensive datasets to identify patterns, predict future events, and detect anomalous behavior across various domains. However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency. Moreover, this review outlines critical trends that are likely to shape the evolution of LLMs in these fields, including the push toward real-time processing, the importance of sustainable modeling practices, and the value of interdisciplinary collaboration. Conclusively, this review underscores the transformative impact LLMs could have on forecasting and anomaly detection while emphasizing the need for continuous innovation, ethical considerations, and practical solutions to realize their full potential.},
	language = {en},
	urldate = {2024-08-19},
	publisher = {arXiv},
	author = {Su, Jing and Jiang, Chufeng and Jin, Xin and Qiao, Yuxin and Xiao, Tingsong and Ma, Hongda and Wei, Rong and Jing, Zhi and Xu, Jiajun and Lin, Junhong},
	month = feb,
	year = {2024},
	note = {arXiv:2402.10350 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{nielsen_neural_2015,
	title = {Neural {Networks} and {Deep} {Learning}},
	language = {en},
	author = {Nielsen, Michael},
	year = {2015},
	pages = {224},
}

@article{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	language = {en},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
}

@misc{yue_ts2vec_2022,
	title = {{TS2Vec}: {Towards} {Universal} {Representation} of {Time} {Series}},
	shorttitle = {{TS2Vec}},
	url = {http://arxiv.org/abs/2106.10466},
	abstract = {This paper presents TS2Vec, a universal framework for learning representations of time series in an arbitrary semantic level. Unlike existing methods, TS2Vec performs contrastive learning in a hierarchical way over augmented context views, which enables a robust contextual representation for each timestamp. Furthermore, to obtain the representation of an arbitrary sub-sequence in the time series, we can apply a simple aggregation over the representations of corresponding timestamps. We conduct extensive experiments on time series classiﬁcation tasks to evaluate the quality of time series representations. As a result, TS2Vec achieves signiﬁcant improvement over existing SOTAs of unsupervised time series representation on 125 UCR datasets and 29 UEA datasets. The learned timestamp-level representations also achieve superior results in time series forecasting and anomaly detection tasks. A linear regression trained on top of the learned representations outperforms previous SOTAs of time series forecasting. Furthermore, we present a simple way to apply the learned representations for unsupervised anomaly detection, which establishes SOTA results in the literature. The source code is publicly available at https://github.com/yuezhihan/ts2vec.},
	language = {en},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Yue, Zhihan and Wang, Yujing and Duan, Juanyong and Yang, Tianmeng and Huang, Congrui and Tong, Yunhai and Xu, Bixiong},
	month = feb,
	year = {2022},
	note = {arXiv:2106.10466 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{li_anomaly_2024,
	title = {Anomaly {Detection} of {Tabular} {Data} {Using} {LLMs}},
	url = {http://arxiv.org/abs/2406.16308},
	abstract = {Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zeroshot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective datagenerating processes to simulate synthetic batchlevel anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Li, Aodong and Zhao, Yunhan and Qiu, Chen and Kloft, Marius and Smyth, Padhraic and Rudolph, Maja and Mandt, Stephan},
	month = jun,
	year = {2024},
	note = {arXiv:2406.16308 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{fung_model_2024,
	title = {Model {Selection} of {Zero}-shot {Anomaly} {Detectors} in the {Absence} of {Labeled} {Validation} {Data}},
	url = {http://arxiv.org/abs/2310.10461},
	abstract = {Anomaly detection requires detecting abnormal samples in large unlabeled datasets. While progress in deep learning and the advent of foundation models has produced powerful zero-shot anomaly detection methods, their deployment in practice is often hindered by the lack of labeled data—without it, their detection performance cannot be evaluated reliably. In this work, we propose SWSA (Selection With Synthetic Anomalies): a general-purpose framework to select image-based anomaly detectors with a generated synthetic validation set. Our proposed anomaly generation method assumes access to only a small support set of normal images and requires no training or finetuning. Once generated, our synthetic validation set is used to create detection tasks that compose a validation framework for model selection. In an empirical study, we find that SWSA often selects models that match selections made with a groundtruth validation set, resulting in higher AUROCs than baseline methods. We also find that SWSA selects prompts for CLIP-based anomaly detection that outperform baseline prompt selection strategies on all datasets, including the challenging MVTec-AD and VisA datasets.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Fung, Clement and Qiu, Chen and Li, Aodong and Rudolph, Maja},
	month = feb,
	year = {2024},
	note = {arXiv:2310.10461 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{li_zero-shot_2023,
	title = {Zero-{Shot} {Anomaly} {Detection} via {Batch} {Normalization}},
	url = {http://arxiv.org/abs/2302.07849},
	abstract = {Anomaly detection (AD) tries to identify data instances that deviate from the norm in a given data set. Since data distributions are subject to distribution shifts, our concept of “normality” may also drift, raising the need for zero-shot adaptation approaches for anomaly detection. However, the fact that current zero-shot AD methods rely on foundation models that are restricted in their domain (natural language and natural images), are costly, and oftentimes proprietary, asks for alternative approaches. In this paper, we propose a simple and highly effective zero-shot AD approach compatible with a variety of established AD methods. Our solution relies on training an off-theshelf anomaly detector (such as a deep SVDD) on a set of inter-related data distributions in combination with batch normalization. This simple recipe–batch normalization plus meta-training–is a highly effective and versatile tool. Our results demonstrate the ﬁrst zero-shot anomaly detection results for tabular data and SOTA zero-shot AD results for image data from specialized domains.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Li, Aodong and Qiu, Chen and Kloft, Marius and Smyth, Padhraic and Rudolph, Maja and Mandt, Stephan},
	month = nov,
	year = {2023},
	note = {arXiv:2302.07849 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{aota_zero-shot_2023,
	address = {Waikoloa, HI, USA},
	title = {Zero-shot versus {Many}-shot: {Unsupervised} {Texture} {Anomaly} {Detection}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-346-8},
	shorttitle = {Zero-shot versus {Many}-shot},
	url = {https://ieeexplore.ieee.org/document/10030870/},
	doi = {10.1109/WACV56688.2023.00552},
	abstract = {Research on unsupervised anomaly detection (AD) has recently progressed, significantly increasing detection accuracy. This paper focuses on texture images and considers how few normal samples are needed for accurate AD. We first highlight the critical nature of the problem that previous studies have overlooked: accurate detection gets harder for anisotropic textures when image orientations are not aligned between inputs and normal samples. We then propose a zero-shot method, which detects anomalies without using a normal sample. The method is free from the issue of unaligned orientation between input and normal images. It assumes the input texture to be homogeneous, detecting image regions that break the homogeneity as anomalies. We present a quantitative criterion to judge whether this assumption holds for an input texture. Experimental results show the broad applicability of the proposed zero-shot method and its good performance comparable to or even higher than the state-of-the-art methods using hundreds of normal samples. The code and data are available from https://drive.google.com/drive/folders/ 10OyPzvI3H6llCZBxKxFlKWt1Pw1tkMK1.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {2023 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Aota, Toshimichi and Tong, Lloyd Teh Tzer and Okatani, Takayuki},
	month = jan,
	year = {2023},
	pages = {5553--5561},
}

@misc{zhou_anomalyclip_2024,
	title = {{AnomalyCLIP}: {Object}-agnostic {Prompt} {Learning} for {Zero}-shot {Anomaly} {Detection}},
	shorttitle = {{AnomalyCLIP}},
	url = {http://arxiv.org/abs/2310.18961},
	abstract = {Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary data to detect anomalies without any training sample in a target dataset. It is a crucial task when training data is not accessible due to various concerns, e.g., data privacy, yet it is challenging since the models need to generalize to anomalies across different domains where the appearance of foreground objects, abnormal regions, and background features, such as defects/tumors on different products/organs, can vary significantly. Recently large pre-trained vision-language models (VLMs), such as CLIP, have demonstrated strong zero-shot recognition ability in various vision tasks, including anomaly detection. However, their ZSAD performance is weak since the VLMs focus more on modeling the class semantics of the foreground objects rather than the abnormality/normality in the images. In this paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains. The key insight of AnomalyCLIP is to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. This allows our model to focus on the abnormal image regions rather than the object semantics, enabling generalized normality and abnormality recognition on diverse types of objects. Large-scale experiments on 17 real-world anomaly detection datasets show that AnomalyCLIP achieves superior zero-shot performance of detecting and segmenting anomalies in datasets of highly diverse class semantics from various defect inspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Zhou, Qihang and Pang, Guansong and Tian, Yu and He, Shibo and Chen, Jiming},
	month = mar,
	year = {2024},
	note = {arXiv:2310.18961 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{jiao_timeautoad_2022,
	title = {{TimeAutoAD}: {Autonomous} {Anomaly} {Detection} {With} {Self}-{Supervised} {Contrastive} {Loss} for {Multivariate} {Time} {Series}},
	volume = {9},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2327-4697, 2334-329X},
	shorttitle = {{TimeAutoAD}},
	url = {https://ieeexplore.ieee.org/document/9705079/},
	doi = {10.1109/TNSE.2022.3148276},
	abstract = {Multivariate time series (MTS) data are becoming increasingly ubiquitous in networked systems, e.g., IoT systems and 5G networks. Anomaly detection in MTS refers to identifying time series which exhibit different behaviors from normal status. Building such a system, however, is challenging due to a few reasons: i) labels for anomaly cases are usually unavailable or very rare; ii) most existing approaches rely on manual model-design and hyperparameter tuning, which may cost a huge amount of labor effort. To this end, we propose an autonomous anomaly detection technique for multivariate time series data (TimeAutoAD) based on a novel self-supervised contrastive loss. Speciﬁcally, we ﬁrst present an automatic anomaly detection pipeline to optimize the model conﬁguration and hyperparameters automatically. Next, we introduce three different strategies to augment the training data for generating pseudo negative time series and employ a self-supervised contrastive loss to distinguish the original time series and the generated time series. In this way, the representation learning capability of TimeAutoAD can be greatly enhanced and the anomaly detection performance can thus be improved. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoAD not only outperforms state-of-the-art anomaly detection approaches but also exhibits robustness when training data are contaminated.},
	language = {en},
	number = {3},
	urldate = {2024-08-01},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Jiao, Yang and Yang, Kai and Song, Dongjing and Tao, Dacheng},
	month = may,
	year = {2022},
	pages = {1604--1619},
}

@inproceedings{lee_time_2023,
	address = {Bali, Indonesia},
	title = {Time {Series} {Anomaly} {Detection} {Using} {Contrastive} {Learning} based {One}-{Class} {Classification}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66545-645-6},
	url = {https://ieeexplore.ieee.org/document/10067089/},
	doi = {10.1109/ICAIIC57133.2023.10067089},
	abstract = {Time series anomaly detection in industrial processes has recently attracted attention. However, since there are no labels in the manufacturing process data collected in real time, there are limitations in using supervised learning-based classification models. Therefore, the proposed method newly defines an objective function that simultaneously learns the OCC model and contrastive learning. In addition, by applying data augmentation techniques suitable for periodic time series data in contrastive learning, feature extraction that preserves temporal characteristics is possible. The effectiveness of representation extraction was verified by showing high anomaly detection performance even in datasets with similar normal and anomaly data forms.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {2023 {International} {Conference} on {Artificial} {Intelligence} in {Information} and {Communication} ({ICAIIC})},
	publisher = {IEEE},
	author = {Lee, Yeseul and Byun, Yunseon and Baek, Jun-Geol},
	month = feb,
	year = {2023},
	pages = {330--335},
}

@article{ngu_cl-tad_2023,
	title = {{CL}-{TAD}: {A} {Contrastive}-{Learning}-{Based} {Method} for {Time} {Series} {Anomaly} {Detection}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	shorttitle = {{CL}-{TAD}},
	url = {https://www.mdpi.com/2076-3417/13/21/11938},
	doi = {10.3390/app132111938},
	abstract = {Anomaly detection has gained increasing attention in recent years, but detecting anomalies in time series data remains challenging due to temporal dynamics, label scarcity, and data diversity in real-world applications. To address these challenges, we introduce a novel method for anomaly detection in time series data, called CL-TAD (Contrastive-Learning-based method for Times series Anomaly Detection), which employs a contrastive-learning-based representation learning technique. Inspired by the successes of reconstruction-based approaches and contrastive learning approaches, the proposed method seeks to leverage these approaches for time series anomaly detection. The CL-TAD method is comprised of two main components: positive sample generation and contrastivelearning-based representation learning. The former component generates positive samples by trying to reconstruct the original data from masked samples. These positive samples, in conjunction with the original data, serve as input for the contrastive-learning-based representation learning component. The representations of input original data and their masked data are used to detect anomalies later on. Experimental results have demonstrated that the CL-TAD method achieved the best performance on ﬁve datasets out of nine benchmark datasets over 10 other recent methods. By leveraging the reconstruction learning and contrastive learning techniques, our method offers a promising solution for effectively detecting anomalies in time series data by handling the issues raised by label scarcity and data diversity, delivering high performance.},
	language = {en},
	number = {21},
	urldate = {2024-08-01},
	journal = {Applied Sciences},
	author = {Ngu, Huynh Cong Viet and Lee, Keon Myung},
	month = oct,
	year = {2023},
	pages = {11938},
}

@inproceedings{su_robust_2019,
	address = {Anchorage AK USA},
	title = {Robust {Anomaly} {Detection} for {Multivariate} {Time} {Series} through {Stochastic} {Recurrent} {Neural} {Network}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330672},
	doi = {10.1145/3292500.3330672},
	abstract = {Industry devices (i.e., entities) such as server machines, spacecrafts, engines, etc., are typically monitored with multivariate time series, whose anomaly detection is critical for an entity’s service quality management. However, due to the complex temporal dependence and stochasticity of multivariate time series, their anomaly detection remains a big challenge. This paper proposes OmniAnomaly, a stochastic recurrent neural network for multivariate time series anomaly detection that works well robustly for various devices. Its core idea is to capture the normal patterns of multivariate time series by learning their robust representations with key techniques such as stochastic variable connection and planar normalizing flow, reconstruct input data by the representations, and use the reconstruction probabilities to determine anomalies. Moreover, for a detected entity anomaly, OmniAnomaly can provide interpretations based on the reconstruction probabilities of its constituent univariate time series. The evaluation experiments are conducted on two public datasets from aerospace and a new server machine dataset (collected and released by us) from an Internet company. OmniAnomaly achieves an overall F1-Score of 0.86 in three real-world datasets, significantly outperforming the best performing baseline method by 0.09. The interpretation accuracy for OmniAnomaly is up to 0.89.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Su, Ya and Zhao, Youjian and Niu, Chenhao and Liu, Rong and Sun, Wei and Pei, Dan},
	month = jul,
	year = {2019},
	pages = {2828--2837},
}

@misc{pranavan_contrastive_2022,
	title = {Contrastive predictive coding for {Anomaly} {Detection} in {Multi}-variate {Time} {Series} {Data}},
	url = {http://arxiv.org/abs/2202.03639},
	abstract = {Anomaly detection in multi-variate time series (MVTS) data is a huge challenge as it requires simultaneous representation of long term temporal dependencies and correlations across multiple variables. More often, this is solved by breaking the complexity through modeling one dependency at a time. In this paper, we propose a Time-series Representational Learning through Contrastive Predictive Coding (TRL-CPC) towards anomaly detection in MVTS data. First, we jointly optimize an encoder, an auto-regressor and a non-linear transformation function to effectively learn the representations of the MVTS data sets, for predicting future trends. It must be noted that the context vectors are representative of the observation window in the MTVS. Next, the latent representations for the succeeding instants obtained through non-linear transformations of these context vectors, are contrasted with the latent representations of the encoder for the multi-variables such that the density for the positive pair is maximized. Thus, the TRL-CPC helps to model the temporal dependencies and the correlations of the parameters for a healthy signal pattern. Finally, ﬁtting the latent representations are ﬁt into a Gaussian scoring function to detect anomalies. Evaluation of the proposed TRL-CPC on three MVTS data sets against SOTA anomaly detection methods shows the superiority of TRL-CPC.},
	language = {en},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Pranavan, Theivendiram and Sim, Terence and Ambikapathi, Arulmurugan and Ramasamy, Savitha},
	month = feb,
	year = {2022},
	note = {arXiv:2202.03639 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ramirez_rivera_anomaly_2022,
	title = {Anomaly {Detection} {Based} on {Zero}-{Shot} {Outlier} {Synthesis} and {Hierarchical} {Feature} {Distillation}},
	volume = {33},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9228891/},
	doi = {10.1109/TNNLS.2020.3027667},
	abstract = {Anomaly detection suffers from unbalanced data since anomalies are quite rare. Synthetically generated anomalies are a solution to such ill or not fully deﬁned data. However, synthesis requires an expressive representation to guarantee the quality of the generated data. In this article, we propose a two-level hierarchical latent space representation that distills inliers’ feature descriptors [through autoencoders (AEs)] into more robust representations based on a variational family of distributions (through a variational AE) for zero-shot anomaly generation. From the learned latent distributions, we select those that lie on the outskirts of the training data as synthetic-outlier generators. Also, we synthesize from them, i.e., generate negative samples without seen them before, to train binary classiﬁers. We found that the use of the proposed hierarchical structure for feature distillation and fusion creates robust and general representations that allow us to synthesize pseudo outlier samples. Also, in turn, train robust binary classiﬁers for true outlier detection (without the need for actual outliers during training). We demonstrate the performance of our proposal on several benchmarks for anomaly detection.},
	language = {en},
	number = {1},
	urldate = {2024-07-30},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Ramirez Rivera, Adin and Khan, Adil and Bekkouch, Imad Eddine Ibrahim and Sheikh, Taimoor Shakeel},
	month = jan,
	year = {2022},
	pages = {281--291},
}

@misc{jeong_time-series_2022,
	title = {Time-{Series} {Anomaly} {Detection} with {Implicit} {Neural} {Representation}},
	url = {http://arxiv.org/abs/2201.11950},
	abstract = {Detecting anomalies in multivariate time-series data is essential in many real-world applications. Recently, various deep learning-based approaches have shown considerable improvements in timeseries anomaly detection. However, existing methods still have several limitations, such as long training time due to their complex model designs or costly tuning procedures to ﬁnd optimal hyperparameters (e.g., sliding window length) for a given dataset. In our paper, we propose a novel method called Implicit Neural Representationbased Anomaly Detection (INRAD). Speciﬁcally, we train a simple multi-layer perceptron that takes time as input and outputs corresponding values at that time. Then we utilize the representation error as an anomaly score for detecting anomalies. Experiments on ﬁve real-world datasets demonstrate that our proposed method outperforms other state-of-the-art methods in performance, training speed, and robustness.},
	language = {en},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Jeong, Kyeong-Joong and Shin, Yong-Min},
	month = jan,
	year = {2022},
	note = {arXiv:2201.11950 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{beggel_time_2019,
	title = {Time series anomaly detection based on shapelet learning},
	volume = {34},
	issn = {0943-4062, 1613-9658},
	url = {http://link.springer.com/10.1007/s00180-018-0824-9},
	doi = {10.1007/s00180-018-0824-9},
	language = {en},
	number = {3},
	urldate = {2024-07-30},
	journal = {Computational Statistics},
	author = {Beggel, Laura and Kausler, Bernhard X. and Schiegg, Martin and Pfeiffer, Michael and Bischl, Bernd},
	month = sep,
	year = {2019},
	pages = {945--976},
}

@inproceedings{alshaer_detecting_2020,
	address = {Baltimore, MD, USA},
	title = {Detecting {Anomalies} from {Streaming} {Time} {Series} using {Matrix} {Profile} and {Shapelets} {Learning}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72819-228-4},
	url = {https://ieeexplore.ieee.org/document/9288261/},
	doi = {10.1109/ICTAI50040.2020.00066},
	abstract = {Detecting anomalies in streaming time series data with no prior labels is considered a challenging issue, especially, when anomalies may vary with time. There is a need to deal with time series streams by identifying the anomalous patterns. These patterns can be described by representative features extracted from the data, which expresses abnormal behavior. This work addresses the challenge of performing online and continuous learning over time series data. In this paper, a solution based on the Matrix Proﬁle algorithm and representation learning approach is developed. In light of that, we will show how the integration of these widely used approaches in the streaming context is quite important for learning and detecting anomalies in realtime.},
	language = {en},
	urldate = {2024-07-30},
	booktitle = {2020 {IEEE} 32nd {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	publisher = {IEEE},
	author = {Alshaer, Mohammad and Garcia-Rodriguez, Sandra and Gouy-Pailler, Cedric},
	month = nov,
	year = {2020},
	pages = {376--383},
}

@inproceedings{pereira_learning_2019,
	address = {Kyoto, Japan},
	title = {Learning {Representations} from {Healthcare} {Time} {Series} {Data} for {Unsupervised} {Anomaly} {Detection}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-5386-7789-6},
	url = {https://ieeexplore.ieee.org/document/8679157/},
	doi = {10.1109/BIGCOMP.2019.8679157},
	abstract = {The amount of time series data generated in Healthcare is growing very fast and so is the need for methods that can analyse these data, detect anomalies and provide meaningful insights. However, most of the data available is unlabelled and, therefore, anomaly detection in this scenario has been a great challenge for researchers and practitioners.},
	language = {en},
	urldate = {2024-07-30},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} and {Smart} {Computing} ({BigComp})},
	publisher = {IEEE},
	author = {Pereira, Joao and Silveira, Margarida},
	month = feb,
	year = {2019},
	pages = {1--7},
}

@book{gardenfors_conceptual_2000,
	address = {Cambridge, Mass},
	title = {Conceptual spaces: the geometry of thought},
	isbn = {978-0-262-07199-4},
	shorttitle = {Conceptual spaces},
	publisher = {MIT Press},
	author = {Gärdenfors, Peter},
	year = {2000},
	keywords = {Artificial intelligence, Cognitive science},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@misc{ma_survey_2023,
	title = {A {Survey} on {Time}-{Series} {Pre}-{Trained} {Models}},
	url = {http://arxiv.org/abs/2305.10716},
	abstract = {Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difﬁcult due to data annotation costs. Recently, Pre-Trained Models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Speciﬁcally, we ﬁrst brieﬂy introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments are conducted to analyze the advantages and disadvantages of transfer learning strategies, Transformer-based models, and representative TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future work. The source code is available at https://github.com/qianlima-lab/time-series-ptms.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Ma, Qianli and Liu, Zhen and Zheng, Zhenjing and Huang, Ziyang and Zhu, Siying and Yu, Zhongzhong and Kwok, James T.},
	month = may,
	year = {2023},
	note = {arXiv:2305.10716 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{goswami_moment_2024,
	title = {{MOMENT}: {A} {Family} of {Open} {Time}-series {Foundation} {Models}},
	shorttitle = {{MOMENT}},
	url = {http://arxiv.org/abs/2402.03885},
	abstract = {We introduce MOMENT, a family of open-source foundation models for general-purpose time series analysis. Pre-training large models on time series data is challenging due to (1) the absence of a large and cohesive public time series repository, and (2) diverse time series characteristics which make multi-dataset training onerous. Additionally, (3) experimental benchmarks to evaluate these models, especially in scenarios with limited resources, time, and supervision, are still in their nascent stages. To address these challenges, we compile a large and diverse collection of public time series, called the Time series Pile, and systematically tackle time series-specific challenges to unlock large-scale multi-dataset pretraining. Finally, we build on recent work to design a benchmark to evaluate time series foundation models on diverse tasks and datasets in limited supervision settings. Experiments on this benchmark demonstrate the effectiveness of our pre-trained models with minimal data and taskspecific fine-tuning. Finally, we present several interesting empirical observations about large pretrained time series models. Pre-trained models (AutonLab/MOMENT-1-large) and Time Series Pile (AutonLab/Timeseries-PILE) are available on https://huggingface.co/AutonLab.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Goswami, Mononito and Szafer, Konrad and Choudhry, Arjun and Cai, Yifu and Li, Shuo and Dubrawski, Artur},
	month = may,
	year = {2024},
	note = {arXiv:2402.03885 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{xu_anomaly_2022,
	title = {Anomaly {Transformer}: {Time} {Series} {Anomaly} {Detection} with {Association} {Discrepancy}},
	shorttitle = {Anomaly {Transformer}},
	url = {http://arxiv.org/abs/2110.02642},
	abstract = {Unsupervised detection of anomaly points in time series is a challenging problem, which requires the model to derive a distinguishable criterion. Previous methods tackle the problem mainly through learning pointwise representation or pairwise association, however, neither is sufﬁcient to reason about the intricate dynamics. Recently, Transformers have shown great power in uniﬁed modeling of pointwise representation and pairwise association, and we ﬁnd that the self-attention weight distribution of each time point can embody rich association with the whole series. Our key observation is that due to the rarity of anomalies, it is extremely difﬁcult to build nontrivial associations from abnormal points to the whole series, thereby, the anomalies’ associations shall mainly concentrate on their adjacent time points. This adjacent-concentration bias implies an association-based criterion inherently distinguishable between normal and abnormal points, which we highlight through the Association Discrepancy. Technically, we propose the Anomaly Transformer with a new Anomaly-Attention mechanism to compute the association discrepancy. A minimax strategy is devised to amplify the normal-abnormal distinguishability of the association discrepancy. The Anomaly Transformer achieves state-of-theart results on six unsupervised time series anomaly detection benchmarks of three applications: service monitoring, space \& earth exploration, and water treatment.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Xu, Jiehui and Wu, Haixu and Wang, Jianmin and Long, Mingsheng},
	month = jun,
	year = {2022},
	note = {arXiv:2110.02642 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{darban_carla_2024,
	title = {{CARLA}: {Self}-supervised {Contrastive} {Representation} {Learning} for {Time} {Series} {Anomaly} {Detection}},
	shorttitle = {{CARLA}},
	url = {http://arxiv.org/abs/2308.09296},
	abstract = {One main challenge in time series anomaly detection (TSAD) is the lack of labelled data in many real-life scenarios. Most of the existing anomaly detection methods focus on learning the normal behaviour of unlabelled time series in an unsupervised manner. The normal boundary is often defined tightly, resulting in slight deviations being classified as anomalies, consequently leading to a high false positive rate and a limited ability to generalise normal patterns. To address this, we introduce a novel end-to-end self-supervised ContrAstive Representation Learning approach for time series Anomaly detection (CARLA). While existing contrastive learning methods assume that augmented time series windows are positive samples and temporally distant windows are negative samples, we argue that these assumptions are limited as augmentation of time series can transform them to negative samples, and a temporally distant window can represent a positive sample. Our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples. Therefore, CARLA not only learns normal behaviour but also learns deviations indicating anomalies. It creates similar representations for temporally closed windows and distinct ones for anomalies. Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection. In extensive tests on seven major real-world time series anomaly detection datasets, CARLA shows superior performance over state-of-the-art self-supervised and unsupervised TSAD methods. Our research shows the potential of contrastive representation learning to advance time series anomaly detection.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Darban, Zahra Zamanzadeh and Webb, Geoffrey I. and Pan, Shirui and Aggarwal, Charu C. and Salehi, Mahsa},
	month = apr,
	year = {2024},
	note = {arXiv:2308.09296 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{gruhl_novelty_2022,
	title = {Novelty {Detection} for {Multivariate} {Data} {Streams} with {Probalistic} {Models}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International, open access},
	url = {https://kobra.uni-kassel.de/handle/123456789/13902},
	doi = {10.17170/KOBRA-202205106160},
	language = {en},
	urldate = {2024-07-15},
	author = {Gruhl, Christian M.},
	collaborator = {{Universität Kassel}},
	year = {2022},
	note = {Publisher: Universität Kassel},
	keywords = {620, Anomalieerkennung, Autonomer Agent, Daten, Datenstrom, Maschinelles Lernen, Sensor, Wahrscheinlichkeitsmaß, anomalies, anomaly detection, concept drift, data streams, machine learning, novelties, novelty detection, outliers, probabilistic modeling},
}

@inproceedings{gangloff_unsupervised_2023,
	address = {Kuala Lumpur, Malaysia},
	title = {Unsupervised {Anomaly} {Detection} {Using} {Variational} {Autoencoder} with {Gaussian} {Random} {Field} {Prior}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-72819-835-4},
	url = {https://ieeexplore.ieee.org/document/10222900/},
	doi = {10.1109/ICIP49359.2023.10222900},
	abstract = {We propose a new model of Variational Autoencoder (VAE) for Anomaly Detection (AD) with improved modeling power. More precisely, we introduce a VAE model with a Gaussian Random Field (GRF) prior, namely VAE-GRF, which generalizes the classical VAE model. We show that, under some assumptions, the VAE-GRF largely outperforms the traditional VAE and some other probabilistic models developed for AD. Our experimental results suggest that the VAE-GRF could be used as a relevant VAE baseline in place of the traditional VAE with very limited additional computational cost. We provide competitive results on the public MVTec benchmark dataset for visual inspection, as well as on the public Livestock dataset dedicated to the task of unsupervised animal detection from aerial images.},
	language = {en},
	urldate = {2024-07-15},
	booktitle = {2023 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Gangloff, Hugo and Pham, Minh-Tan and Courtrai, Luc and Lefèvre, Sébastien},
	month = oct,
	year = {2023},
	pages = {1620--1624},
}

@inproceedings{gangloff_leveraging_2022,
	address = {Montreal, QC, Canada},
	title = {Leveraging {Vector}-{Quantized} {Variational} {Autoencoder} {Inner} {Metrics} for {Anomaly} {Detection}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-062-7},
	url = {https://ieeexplore.ieee.org/document/9956102/},
	doi = {10.1109/ICPR56361.2022.9956102},
	abstract = {Anomaly Detection (AD) is an important research topic, with very diverse applications such as industrial defect detection, medical diagnosis, fraud detection, intrusion detection, etc. Within the last few years, deep learning-based methods have become the standard approach for AD. In many practical cases, the anomalies are unknown in advance. Therefore, most of challenging AD problems need to be addressed in an unsupervised or weakly supervised framework. In this context, deep generative models are widely used, in particular Variational Autoencoder (VAE) models. VAEs have been extended to Vector-Quantized VAEs (VQ-VAEs), a model increasingly popular because of its versatility enabled by the discrete latent space. We present for the first time a robust approach which takes advantage of the inner metrics of VQ-VAEs for AD. We show that the distance between the output of the encoder and the codebook vectors of a VQ-VAE provides a valuable information which can be used to localize the anomalies. In our approach, this metric complements a reconstruction-based metric to improve AD results. We compare our model with state-of-the-art AD models on three standards datasets, including the MVTec, UCSD-Ped1 and CIFAR-10 datasets. Experiments show that the proposed method yields high competitive results.},
	language = {en},
	urldate = {2024-07-15},
	booktitle = {2022 26th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Gangloff, Hugo and Pham, Minh-Tan and Courtrai, Luc and Lefevre, Sebastien},
	month = aug,
	year = {2022},
	pages = {435--441},
}

@article{palatucci_zero-shot_2009,
	title = {Zero-shot {Learning} with {Semantic} {Output} {Codes}},
	abstract = {We consider the problem of zero-shot learning, where the goal is to learn a classiﬁer f : X → Y that must predict novel values of Y that were omitted from the training set. To achieve this, we deﬁne the notion of a semantic output code classiﬁer (SOC) which utilizes a knowledge base of semantic properties of Y to extrapolate to novel classes. We provide a formalism for this type of classiﬁer and study its theoretical properties in a PAC framework, showing conditions under which the classiﬁer can accurately predict novel classes. As a case study, we build a SOC classiﬁer for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images (fMRI) of their neural activity, even without training examples for those words.},
	language = {en},
	author = {Palatucci, Mark and Pomerleau, Dean and Hinton, Geoffrey E and Mitchell, Tom M},
	year = {2009},
}

@misc{socher_zero-shot_2013,
	title = {Zero-{Shot} {Learning} {Through} {Cross}-{Modal} {Transfer}},
	url = {http://arxiv.org/abs/1301.3666},
	abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the objects. The only necessary knowledge about the unseen categories comes from unsupervised large text corpora. In our zero-shot framework distributional information in language can be seen as spanning a semantic basis for understanding what objects look like. Most previous zero-shot learning models can only differentiate between unseen classes. In contrast, our model can both obtain state of the art performance on classes that have thousands of training images and obtain reasonable performance on unseen classes. This is achieved by ﬁrst using outlier detection in the semantic space and then two separate recognition models. Furthermore, our model does not require any manually deﬁned semantic features for either words or images.},
	language = {en},
	urldate = {2024-07-14},
	publisher = {arXiv},
	author = {Socher, Richard and Ganjoo, Milind and Sridhar, Hamsa and Bastani, Osbert and Manning, Christopher D. and Ng, Andrew Y.},
	month = mar,
	year = {2013},
	note = {arXiv:1301.3666 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Machine learning},
}

@article{sun_survey_2021,
	title = {A {Survey} on {Deep} {Learning} for {Data}-{Driven} {Soft} {Sensors}},
	volume = {17},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/9329169/},
	doi = {10.1109/TII.2021.3053128},
	abstract = {Soft sensors are widely constructed in process industry to realize process monitoring, quality prediction, and many other important applications. With the development of hardware and software, industrial processes have embraced new characteristics, which lead to the poor performance of traditional soft sensor modeling methods. Deep learning, as a kind of data-driven approach, shows its great potential in many ﬁelds, as well as in soft sensing scenarios. After a period of development, especially in the last ﬁve years, many new issues have emerged that need to be investigated. Therefore, in this article, the necessity and signiﬁcance of deep learning for soft sensor applications are demonstrated ﬁrst by analyzing the merits of deep learning and the trends of industrial processes. Next, mainstream deep learning models, tricks, and frameworks/toolkits are summarized and discussed to help designers propel the developing progress of soft sensors. Then, existing works are reviewed and analyzed to discuss the demands and problems occurred in practical applications. Finally, outlook and conclusions are given.},
	language = {en},
	number = {9},
	urldate = {2024-07-14},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Sun, Qingqiang and Ge, Zhiqiang},
	month = sep,
	year = {2021},
	pages = {5853--5866},
}

@article{zhang_debiased_2024,
	title = {Debiased {Contrastive} {Learning} for {Time}-{Series} {Representation} {Learning} and {Fault} {Detection}},
	volume = {20},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/10443248/},
	doi = {10.1109/TII.2024.3359409},
	abstract = {Building reliable fault detection systems through deep neural networks is an appealing topic in industrial scenarios. In these contexts, the representations extracted by neural networks on available labeled timeseries data can reﬂect system states. However, this endeavor remains challenging due to the necessity of labeled data. Self-supervised contrastive learning (SSCL) is one of the effective approaches to deal with this challenge, but existing SSCL-based models suffer from sampling bias and representation bias problems. This article introduces a debiased contrastive learning framework for time-series data and applies it to industrial fault detection tasks. This framework ﬁrst develops the multigranularity augmented view generation method to generate augmented views at different granularities. It then introduces the momentum clustering contrastive learning strategy and the expert knowledge guidance mechanism to mitigate sampling bias and representation bias, respectively. Finally, the experiments on a public bearing fault detection dataset and a widely used valve stiction detection dataset show the effectiveness of the proposed feature learning framework.},
	language = {en},
	number = {5},
	urldate = {2024-07-09},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Zhang, Kexin and Cai, Rongyao and Zhou, Chunlin and Liu, Yong},
	month = may,
	year = {2024},
	pages = {7641--7653},
}

@book{lavrac_representation_2021,
	address = {Cham},
	title = {Representation {Learning}: {Propositionalization} and {Embeddings}},
	copyright = {https://www.springer.com/tdm},
	isbn = {978-3-030-68816-5 978-3-030-68817-2},
	shorttitle = {Representation {Learning}},
	url = {https://link.springer.com/10.1007/978-3-030-68817-2},
	language = {en},
	urldate = {2024-07-09},
	publisher = {Springer International Publishing},
	author = {Lavrač, Nada and Podpečan, Vid and Robnik-Šikonja, Marko},
	year = {2021},
	doi = {10.1007/978-3-030-68817-2},
}

@article{zhuang_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Transfer} {Learning}},
	volume = {109},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	url = {https://ieeexplore.ieee.org/document/9134370/},
	doi = {10.1109/JPROC.2020.3004555},
	language = {en},
	number = {1},
	urldate = {2024-07-03},
	journal = {Proceedings of the IEEE},
	author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
	month = jan,
	year = {2021},
	pages = {43--76},
}

@article{zhang_survey_2022,
	title = {A {Survey} on {Multi}-{Task} {Learning}},
	volume = {34},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/9392366/},
	doi = {10.1109/TKDE.2021.3070203},
	abstract = {Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications and theoretical analyses. For algorithmic modeling, we give a deﬁnition of MTL and then classify different MTL algorithms into ﬁve categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works in this paper. Finally, we present theoretical analyses and discuss several future directions for MTL.},
	language = {en},
	number = {12},
	urldate = {2024-07-03},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Yu and Yang, Qiang},
	month = dec,
	year = {2022},
	pages = {5586--5609},
}

@article{bengio_representation_2013,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	volume = {35},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828, 2160-9292},
	shorttitle = {Representation {Learning}},
	url = {http://ieeexplore.ieee.org/document/6472238/},
	doi = {10.1109/TPAMI.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	language = {en},
	number = {8},
	urldate = {2024-07-03},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Y. and Courville, A. and Vincent, P.},
	month = aug,
	year = {2013},
	pages = {1798--1828},
}

@article{kutbi_zero-shot_2021,
	title = {Zero-shot {Deep} {Domain} {Adaptation} with {Common} {Representation} {Learning}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/9361131/},
	doi = {10.1109/TPAMI.2021.3061204},
	abstract = {Domain Adaptation aims at adapting the knowledge learned from a domain (source-domain) to another (target-domain). Existing approaches typically require a portion of task-relevant target-domain data a priori. We propose an approach, zero-shot deep domain adaptation (ZDDA), which uses paired dual-domain task-irrelevant data to eliminate the need for task-relevant target-domain training data. ZDDA learns to generate common representations for source and target domains data. Then, either domain representation is used later to train a system that works on both domains or having the ability to eliminate the need to either domain in sensor fusion settings. Two variants of ZDDA have been developed: ZDDA for classiﬁcation task (ZDDA-C) and ZDDA for metric learning task (ZDDAML). Another limitation in Existing approaches is that most of them are designed for the closed-set classiﬁcation task, i.e., the sets of classes in both the source and target domains are “known.” However, ZDDA-C is also applicable to the open-set classiﬁcation task where not all classes are “known” during training. Moreover, the effectiveness of ZDDA-ML shows ZDDA’s applicability is not limited to classiﬁcation tasks. ZDDA-C and ZDDA-ML are tested on classiﬁcation and metric-learning tasks, respectively. Under most experimental conditions, ZDDA outperforms the baseline without using task-relevant target-domain-training data.},
	language = {en},
	urldate = {2024-06-28},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Kutbi, Mohammed and Peng, Kuan-Chuan and Wu, Ziyan},
	year = {2021},
	pages = {1--1},
}

@article{nivarthi_multi-task_2023,
	title = {Multi-{Task} {Representation} {Learning} for {Renewable}-{Power} {Forecasting}: {A} {Comparative} {Analysis} of {Unified} {Autoencoder} {Variants} and {Task}-{Embedding} {Dimensions}},
	volume = {5},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2504-4990},
	shorttitle = {Multi-{Task} {Representation} {Learning} for {Renewable}-{Power} {Forecasting}},
	url = {https://www.mdpi.com/2504-4990/5/3/62},
	doi = {10.3390/make5030062},
	abstract = {Typically, renewable-power-generation forecasting using machine learning involves creating separate models for each photovoltaic or wind park, known as single-task learning models. However, transfer learning has gained popularity in recent years, as it allows for the transfer of knowledge from source parks to target parks. Nevertheless, determining the most similar source park(s) for transfer learning can be challenging, particularly when the target park has limited or no historical data samples. To address this issue, we propose a multi-task learning architecture that employs a Uniﬁed Autoencoder (UAE) to initially learn a common representation of input weather features among tasks and then utilizes a Task-Embedding layer in a Neural Network (TENN) to learn task-speciﬁc information. This proposed UAE-TENN architecture can be easily extended to new parks with or without historical data. We evaluate the performance of our proposed architecture and compare it to single-task learning models on six photovoltaic and wind farm datasets consisting of a total of 529 parks. Our results show that the UAE-TENN architecture signiﬁcantly improves power-forecasting performance by 10 to 19\% for photovoltaic parks and 5 to 15\% for wind parks compared to baseline models. We also demonstrate that UAE-TENN improves forecast accuracy for a new park by 19\% for photovoltaic parks, even in a zero-shot learning scenario where there is no historical data. Additionally, we propose variants of the Uniﬁed Autoencoder with convolutional and LSTM layers, compare their performance, and provide a comparison among architectures with different numbers of task-embedding dimensions. Finally, we demonstrate the utility of trained task embeddings for interpretation and visualization purposes.},
	language = {en},
	number = {3},
	urldate = {2024-06-27},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Nivarthi, Chandana Priya and Vogt, Stephan and Sick, Bernhard},
	month = sep,
	year = {2023},
	pages = {1214--1233},
}

@misc{nivarthi_transfer_2022,
	title = {Transfer {Learning} as an {Essential} {Tool} for {Digital} {Twins} in {Renewable} {Energy} {Systems}},
	url = {http://arxiv.org/abs/2203.05026},
	abstract = {Transfer learning (TL), the next frontier in machine learning (ML), has gained much popularity in recent years, due to the various challenges faced in ML, like the requirement of vast amounts of training data, expensive and time-consuming labelling processes for data samples, and long training duration for models. TL is useful in tackling these problems, as it focuses on transferring knowledge from previously solved tasks to new tasks. Digital twins and other intelligent systems need to utilise TL to use the previously gained knowledge and solve new tasks in a more self-reliant way, and to incrementally increase their knowledge base. Therefore, in this article, the critical challenges in power forecasting and anomaly detection in the context of renewable energy systems are identiﬁed, and a potential TL framework to meet these challenges is proposed. This article also proposes a feature embedding approach to handle the missing sensors data. The proposed TL methods help to make a system more autonomous in the context of organic computing.},
	language = {en},
	urldate = {2024-06-27},
	publisher = {arXiv},
	author = {Nivarthi, Chandana Priya},
	month = mar,
	year = {2022},
	note = {arXiv:2203.05026 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{nivarthi_unified_2022,
	address = {Nassau, Bahamas},
	title = {Unified {Autoencoder} with {Task} {Embeddings} for {Multi}-{Task} {Learning} in {Renewable} {Power} {Forecasting}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66546-283-9},
	url = {https://ieeexplore.ieee.org/document/10068974/},
	doi = {10.1109/ICMLA55696.2022.00240},
	abstract = {Renewable power generation forecasts using machine learning are typically implemented as single-task learning models, where a separate model is trained for each photovoltaic or wind park. In recent years, transfer learning is gaining popularity in these systems, as it can be used to transfer the knowledge gained from source parks to a target park. However, for transferring the knowledge to a target park, there is a need to determine the most similar source park(s) among the existing parks. This similarity determination using historical power measurements is challenging when the target park has limited to no historical data samples. Therefore, we propose a simple multi-task learning architecture that initially learns a common representation of input weather features among the tasks, using a Unified Autoencoder (UAE) and then learns the task specific information utilizing a Task Embedding layer in a Neural Network (TENN). This proposed architecture, UAE-TENN, can be easily extended to new parks with or without historical data. An elaborate performance comparison of single and multi-task learning models is performed on six photovoltaic and wind farm datasets comprising a total of 529 parks. UAE-TENN significantly improves the performance of power forecasting by 10 to 19\% for photovoltaic parks and 5 to 22\% for wind parks compared to the baseline models. Even in the zero-shot learning scenario, when there is no historical data, we successfully demonstrate that the UAE-TENN improves the forecast accuracy for a new park by 19\% for photovoltaic parks.},
	language = {en},
	urldate = {2024-06-27},
	booktitle = {2022 21st {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Nivarthi, Chandana Priya and Vogt, Stephan and Sick, Bernhard},
	month = dec,
	year = {2022},
	pages = {1530--1536},
}

@inproceedings{nivarthi_towards_2023,
	address = {Jacksonville, FL, USA},
	title = {Towards {Few}-{Shot} {Time} {Series} {Anomaly} {Detection} with {Temporal} {Attention} and {Dynamic} {Thresholding}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350345346},
	url = {https://ieeexplore.ieee.org/document/10459893/},
	doi = {10.1109/ICMLA58977.2023.00218},
	abstract = {Anomaly detection plays a pivotal role in diverse realworld applications such as cybersecurity, fault detection, network monitoring, predictive maintenance, and highly automated driving. However, obtaining labeled anomalous data can be a formidable challenge, especially when anomalies exhibit temporal evolution. This paper introduces LATAM (Long short-term memory Autoencoder with Temporal Attention Mechanism) for few-shot anomaly detection, with the aim of enhancing detection performance in scenarios with limited labeled anomaly data. LATAM effectively captures temporal dependencies and emphasizes signiﬁcant patterns in multivariate time series data. In our investigation, we comprehensively evaluate LATAM against other anomaly detection models, particularly assessing its capability in few-shot learning scenarios where we have minimal examples from the normal class and none from the anomalous class in the training data. Our experimental results, derived from real-world photovoltaic inverter data, highlight LATAM’s superiority, showcasing a substantial 27\% mean F1 score improvement, even when trained on a mere two-week dataset. Furthermore, LATAM demonstrates remarkable results on the open-source SWaT dataset, achieving a 12\% boost in accuracy with only two days of training data. Moreover, we introduce a simple yet effective dynamic thresholding mechanism, further enhancing the anomaly detection capabilities of LATAM. This underscores LATAM’s efﬁcacy in addressing the challenges posed by limited labeled anomalies in practical scenarios and it proves valuable for downstream tasks involving temporal representation and time series prediction, extending its utility beyond anomaly detection applications.},
	language = {en},
	urldate = {2024-06-27},
	booktitle = {2023 {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	publisher = {IEEE},
	author = {Nivarthi, Chandana Priya and Sick, Bernhard},
	month = dec,
	year = {2023},
	pages = {1444--1450},
}

@misc{schwartz_maeday_2024,
	title = {{MAEDAY}: {MAE} for few and zero shot {AnomalY}-{Detection}},
	shorttitle = {{MAEDAY}},
	url = {http://arxiv.org/abs/2211.14307},
	abstract = {We propose using Masked Auto-Encoder (MAE), a transformer model self-supervisedly trained on image inpainting, for anomaly detection (AD). Assuming anomalous regions are harder to reconstruct compared with normal regions. MAEDAY is the first image-reconstruction-based anomaly detection method that utilizes a pre-trained model, enabling its use for Few-Shot Anomaly Detection (FSAD). We also show the same method works surprisingly well for the novel tasks of Zero-Shot AD (ZSAD) and Zero-Shot Foreign Object Detection (ZSFOD), where no normal samples are available.},
	language = {en},
	urldate = {2024-06-27},
	publisher = {arXiv},
	author = {Schwartz, Eli and Arbelle, Assaf and Karlinsky, Leonid and Harary, Sivan and Scheidegger, Florian and Doveh, Sivan and Giryes, Raja},
	month = feb,
	year = {2024},
	note = {arXiv:2211.14307 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}
