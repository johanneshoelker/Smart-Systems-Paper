
@misc{sun_unraveling_2023,
	title = {Unraveling the "{Anomaly}" in {Time} {Series} {Anomaly} {Detection}: {A} {Self}-supervised {Tri}-domain {Solution}},
	shorttitle = {Unraveling the "{Anomaly}" in {Time} {Series} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2311.11235},
	abstract = {The ongoing challenges in time series anomaly detection (TSAD), including the scarcity of anomaly labels and the variability in anomaly lengths and shapes, have led to the need for a more robust and efficient solution. As limited anomaly labels hinder traditional supervised models in anomaly detection, various state-of-the-art (SOTA) deep learning techniques (e.g., self-supervised learning) are introduced to tackle this issue. However, they encounter difficulties handling variations in anomaly lengths and shapes, limiting their adaptability to diverse anomalies. Additionally, many benchmark datasets suffer from the problem of having explicit anomalies that even random functions can detect. This problem is exacerbated by an illposed evaluation metric, known as point adjustment (PA), which results in inflated model performance. In this context, we propose a novel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which addresses these challenges by modeling features across three aspects - temporal, frequency, and residual domains - without relying on anomaly labels. Unlike traditional contrastive learning methods, TriAD employs both inter-domain and intra-domain contrastive loss to learn common attributes among normal data and differentiate them from anomalies. Additionally, our approach can detect anomalies of varying lengths by integrating with a discord discovery algorithm. It is worth noting that this study is the first to reevaluate the deep learning potential in TSAD, utilizing both rigorously designed datasets (i.e., UCR Archive) and evaluation metrics (i.e., PA\%K and affiliation). Experimental results demonstrate that TriAD achieves an impressive three-fold increase in PA\%K based F1 scores over SOTA deep learning models. Moreover, in comparison to SOTA discord discovery algorithms, TriAD improves anomaly detection accuracy by 50\% while cutting the inference time down to just one-tenth. Illuminating the significance of rigorous datasets and evaluation metrics, this paper offers a new direction for addressing the multifaceted challenges of time series anomaly detection. The source code is publicly available at https://github.com/pseudo-Skye/TriAD.},
	language = {en},
	urldate = {2024-08-27},
	publisher = {arXiv},
	author = {Sun, Yuting and Pang, Guansong and Ye, Guanhua and Chen, Tong and Hu, Xia and Yin, Hongzhi},
	month = nov,
	year = {2023},
	note = {arXiv:2311.11235 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{chen_time-series_2023,
	title = {Time-series {Anomaly} {Detection} via {Contextual} {Discriminative} {Contrastive} {Learning}},
	url = {http://arxiv.org/abs/2304.07898},
	abstract = {Detecting anomalies in temporal data is challenging due to anomalies being dependent on temporal dynamics. One-class classiﬁcation methods are commonly used for anomaly detection tasks, but they have limitations when applied to temporal data. In particular, mapping all normal instances into a single hypersphere to capture their global characteristics can lead to poor performance in detecting context-based anomalies where the abnormality is deﬁned with respect to local information. To address this limitation, we propose a novel approach inspired by the loss function of DeepSVDD. Instead of mapping all normal instances into a single hypersphere center, each normal instance is pulled toward a recent context window. However, this approach is prone to a representation collapse issue where the neural network that encodes a given instance and its context is optimized towards a constant encoder solution. To overcome this problem, we combine our approach with a deterministic contrastive loss from Neutral AD, a promising self-supervised learning anomaly detection approach. We provide a theoretical analysis to demonstrate that the incorporation of the deterministic contrastive loss can eﬀectively prevent the occurrence of a constant encoder solution. Experimental results show superior performance of our model over various baselines and model variants on real-world industrial datasets.},
	language = {en},
	urldate = {2024-08-27},
	publisher = {arXiv},
	author = {Chen, Katrina and Feng, Mingbin and Wirjanto, Tony S.},
	month = apr,
	year = {2023},
	note = {arXiv:2304.07898 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{qin_multiview_2023,
	title = {Multiview {Graph} {Contrastive} {Learning} for {Multivariate} {Time}-{Series} {Anomaly} {Detection} in {IoT}},
	volume = {10},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/10214266/},
	doi = {10.1109/JIOT.2023.3303946},
	abstract = {Internet of Things (IoT) systems typically generate large amounts of sensory signals that get involved to represent the states of the systems. Most existing methods focus on learning the temporal patterns of the signals to detect anomalies. However, the performance is limited due to two critical problems. First, the relationships between different signals are rarely considered, resulting in missing important information for representation. Second, the high sensitivity of time series makes it difﬁcult to use conventional methods for data augmentation, which limits the improvement of representation and generalization capabilities. In this work, we propose a novel reconstruction-based framework with contrastive learning from multiple views to address these two issues. Speciﬁcally, intrasignal and intersignal graph structures are formed and learned in parallel to model the temporal context and capture the dependency relationships between signals, respectively. Multiview graph contrastive learning strategy is designed to improve the graph representation. We also provide an adaptive data augmentation method to generate graph views for contrastive learning, which helps to accurately capture valuable intrinsic patterns from two different perspectives. Finally, the contrastive learning task and the reconstruction task are jointly trained. Extensive experiments on four real-world data sets demonstrate that our method outperforms the existing state-of-the-art baselines.},
	language = {en},
	number = {24},
	urldate = {2024-08-27},
	journal = {IEEE Internet of Things Journal},
	author = {Qin, Shuxin and Chen, Lin and Luo, Yongcan and Tao, Gaofeng},
	month = dec,
	year = {2023},
	pages = {22401--22414},
}

@inproceedings{yang_dcdetector_2023,
	title = {{DCdetector}: {Dual} {Attention} {Contrastive} {Representation} {Learning} for {Time} {Series} {Anomaly} {Detection}},
	shorttitle = {{DCdetector}},
	url = {http://arxiv.org/abs/2306.10347},
	doi = {10.1145/3580305.3599295},
	abstract = {Time series anomaly detection is critical for a wide range of applications. It aims to identify deviant samples from the normal sample distribution in time series. The most fundamental challenge for this task is to learn a representation map that enables effective discrimination of anomalies. Reconstruction-based methods still dominate, but the representation learning with anomalies might hurt the performance with its large abnormal loss. On the other hand, contrastive learning aims to find a representation that can clearly distinguish any instance from the others, which can bring a more natural and promising representation for time series anomaly detection. In this paper, we propose DCdetector, a multi-scale dual attention contrastive representation learning model. DCdetector utilizes a novel dual attention asymmetric design to create the permutated environment and pure contrastive loss to guide the learning process, thus learning a permutation invariant representation with superior discrimination abilities. Extensive experiments show that DCdetector achieves state-of-the-art results on multiple time series anomaly detection benchmark datasets. Code is publicly available at this URL1.},
	language = {en},
	urldate = {2024-08-27},
	booktitle = {Proceedings of the 29th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Yang, Yiyuan and Zhang, Chaoli and Zhou, Tian and Wen, Qingsong and Sun, Liang},
	month = aug,
	year = {2023},
	note = {arXiv:2306.10347 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	pages = {3033--3045},
}

@misc{wang_deep_2023,
	title = {Deep {Contrastive} {One}-{Class} {Time} {Series} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2207.01472},
	abstract = {The accumulation of time-series data and the absence of labels make time-series Anomaly Detection (AD) a selfsupervised deep learning task. Single-normality-assumptionbased methods, which reveal only a certain aspect of the whole normality, are incapable of tasks involved with a large number of anomalies. Speciﬁcally, Contrastive Learning (CL) methods distance negative pairs, many of which consist of both normal samples, thus reducing the AD performance. Existing multi-normality-assumption-based methods are usually two-staged, ﬁrstly pre-training through certain tasks whose target may diﬀer from AD, limiting their performance. To overcome the shortcomings, a deep Contrastive One-Class Anomaly detection method of time series (COCA) is proposed by authors, following the normality assumptions of CL and one-class classiﬁcation. It treats the original and reconstructed representations as the positive pair of negative-sample-free CL, namely “sequence contrast”. Next, invariance terms and variance terms compose a contrastive one-class loss function in which the loss of the assumptions is optimized by invariance terms simultaneously and the “hypersphere collapse” is prevented by variance terms. In addition, extensive experiments on two realworld time-series datasets show the superior performance of the proposed method achieves state-of-the-art.},
	language = {en},
	urldate = {2024-08-27},
	publisher = {arXiv},
	author = {Wang, Rui and Liu, Chongwei and Mou, Xudong and Gao, Kai and Guo, Xiaohui and Liu, Pin and Wo, Tianyu and Liu, Xudong},
	month = apr,
	year = {2023},
	note = {arXiv:2207.01472 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{kang_tictok_2023,
	title = {{TiCTok}: {Time}-{Series} {Anomaly} {Detection} {With} {Contrastive} {Tokenization}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	shorttitle = {{TiCTok}},
	url = {https://ieeexplore.ieee.org/document/10201844/},
	doi = {10.1109/ACCESS.2023.3301140},
	abstract = {Detecting anomalies in multivariate time-series data is an important task in various real world applications. Recent advances using deep learning have shown promising results in this area. Nowadays, Transformer-based models have shown outstanding performance and contrastive learning has emerged as a powerful technique for representation learning, however, it may not be directly applicable to the time-series domain. Here, we propose a time-series anomaly detection model with contrastive tokenization (TiCTok). We propose a time-series token encoder to transform raw time-series data into latent embeddings containing high-level wide-range temporal information. We exploit both token encoder and contrastive learning to produce high quality latent embeddings. In addition, we propose a novel anomaly scoring method simply utilizing the contrastive loss used in the training phase. According to our experimental results, the proposed model achieved better or comparable performance compared to the previous state-of-the-art on five widely used benchmark datasets in terms of F1-score.},
	language = {en},
	urldate = {2024-08-27},
	journal = {IEEE Access},
	author = {Kang, Minseo and Lee, Byunghan},
	year = {2023},
	pages = {81011--81020},
}

@inproceedings{li_contrastive_2023,
	address = {Gold Coast, Australia},
	title = {Contrastive {Time} {Series} {Anomaly} {Detection} by {Temporal} {Transformations}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66548-867-9},
	url = {https://ieeexplore.ieee.org/document/10191358/},
	doi = {10.1109/IJCNN54540.2023.10191358},
	abstract = {Detecting anomalies in time series data is challenging due to their complex and volatile temporal features. Some anomalies only show deviating patterns to their local context instead of the overall distribution. Additionally, the biased sample distribution between normal and abnormal classes hinders the efficient usage of the available data labels. Self-supervised approaches are practically efficient for anomaly detection, in which only normal data is used during the training. However, they often fail to detect contextual anomalies in high-dimensional time series data, while the representation learning of such complex data patterns is sub-optimal.},
	language = {en},
	urldate = {2024-08-27},
	booktitle = {2023 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Li, Bin and Müller, Emmanuel},
	month = jun,
	year = {2023},
	pages = {1--8},
}

@article{schmidl_anomaly_2022,
	title = {Anomaly detection in time series: a comprehensive evaluation},
	volume = {15},
	issn = {2150-8097},
	shorttitle = {Anomaly detection in time series},
	url = {https://dl.acm.org/doi/10.14778/3538598.3538602},
	doi = {10.14778/3538598.3538602},
	abstract = {Detecting anomalous subsequences in time series data is an important task in areas ranging from manufacturing processes over finance applications to health care monitoring. An anomaly can indicate important events, such as production faults, delivery bottlenecks, system defects, or heart flicker, and is therefore of central interest. Because time series are often large and exhibit complex patterns, data scientists have developed various specialized algorithms for the automatic detection of such anomalous patterns. The number and variety of anomaly detection algorithms has grown significantly in the past and, because many of these solutions have been developed independently and by different research communities, there is no comprehensive study that systematically evaluates and compares the different approaches. For this reason, choosing the best detection technique for a given anomaly detection task is a difficult challenge.},
	language = {en},
	number = {9},
	urldate = {2024-08-25},
	journal = {Proceedings of the VLDB Endowment},
	author = {Schmidl, Sebastian and Wenig, Phillip and Papenbrock, Thorsten},
	month = may,
	year = {2022},
	pages = {1779--1797},
}

@article{lee_impact_nodate,
	title = {Impact of {Recurrent} {Neural} {Networks} and {Deep} {Learning} {Frameworks} on {Real}-time {Lightweight} {Time} {Series} {Anomaly} {Detection}},
	abstract = {Real-time lightweight time series anomaly detection has become increasingly crucial in cybersecurity and many other domains. Its ability to adapt to unforeseen pattern changes and swiftly identify anomalies enables prompt responses and critical decision-making. While several such anomaly detection approaches have been introduced in recent years, they primarily utilize a single type of recurrent neural networks (RNNs) and have been implemented in only one deep learning framework. It is unclear how the use of different types of RNNs available in various deep learning frameworks affects the performance of these anomaly detection approaches due to the absence of comprehensive evaluations. Arbitrarily choosing a RNN variant and a deep learning framework to implement an anomaly detection approach may not reflect its true performance and could potentially mislead users into favoring one approach over another. In this paper, we aim to study the influence of various types of RNNs available in popular deep learning frameworks on real-time lightweight time series anomaly detection. We reviewed several state-of-the-art approaches and implemented a representative anomaly detection approach using well-known RNN variants supported by three widely recognized deep learning frameworks. A comprehensive evaluation is then conducted to analyze the performance of each implementation across real-world, open-source time series datasets. The evaluation results provide valuable guidance for selecting the appropriate RNN variant and deep learning framework for real-time, lightweight time series anomaly detection.},
	language = {en},
	author = {Lee’, Ming-Chang and Lin, Jia-Chun and Katsikas, Sokratis},
}

@article{altin_exploring_2024,
	title = {Exploring the {Influence} of {Dimensionality} {Reduction} on {Anomaly} {Detection} {Performance} in {Multivariate} {Time} {Series}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10559232/},
	doi = {10.1109/ACCESS.2024.3415088},
	abstract = {This paper presents an extensive empirical study on the integration of dimensionality reduction techniques with advanced unsupervised time series anomaly detection models, focusing on the MUTANT and Anomaly-Transformer models. The study involves a comprehensive evaluation across three different datasets: MSL, SMAP, and SWaT. Each dataset poses unique challenges, allowing for a robust assessment of the models’ capabilities in varied contexts. The dimensionality reduction techniques examined include PCA, UMAP, Random Projection, and t-SNE, each offering distinct advantages in simplifying highdimensional data. Our findings reveal that dimensionality reduction not only aids in reducing computational complexity but also significantly enhances anomaly detection performance in certain scenarios. Moreover, a remarkable reduction in training times was observed, with reductions by approximately 300\% and 650\% when dimensionality was halved and minimized to the lowest dimensions, respectively. This efficiency gain underscores the dual benefit of dimensionality reduction in both performance enhancement and operational efficiency. The MUTANT model exhibits notable adaptability, especially with UMAP reduction, while the Anomaly-Transformer demonstrates versatility across various reduction techniques. These insights provide a deeper understanding of the synergistic effects of dimensionality reduction and anomaly detection, contributing valuable perspectives to the field of time series analysis. The study underscores the importance of selecting appropriate dimensionality reduction strategies based on specific model requirements and dataset characteristics, paving the way for more efficient, accurate, and scalable solutions in anomaly detection.},
	language = {en},
	urldate = {2024-08-25},
	journal = {IEEE Access},
	author = {Altin, Mahsun and Cakir, Altan},
	year = {2024},
	pages = {85783--85794},
}

@article{garg_evaluation_2022,
	title = {An {Evaluation} of {Anomaly} {Detection} and {Diagnosis} in {Multivariate} {Time} {Series}},
	volume = {33},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9525836/},
	doi = {10.1109/TNNLS.2021.3105827},
	abstract = {Several techniques for multivariate time series anomaly detection have been proposed recently, but a systematic comparison on a common set of datasets and metrics is lacking. This article presents a systematic and comprehensive evaluation of unsupervised and semisupervised deep-learning-based methods for anomaly detection and diagnosis on multivariate time series data from cyberphysical systems. Unlike previous works, we vary the model and post-processing of model errors, i.e., the scoring functions independently of each other, through a grid of ten models and four scoring functions, comparing these variants to state-of-the-art methods. In time-series anomaly detection, detecting anomalous events is more important than detecting individual anomalous time points. Through experiments, we ﬁnd that the existing evaluation metrics either do not take events into account or cannot distinguish between a good detector and trivial detectors, such as a random or an all-positive detector. We propose a new metric to overcome these drawbacks, namely, the composite F-score (Fc1), for evaluating time-series anomaly detection. Our study highlights that dynamic scoring functions work much better than static ones for multivariate time series anomaly detection, and the choice of scoring functions often matters more than the choice of the underlying model. We also ﬁnd that a simple, channel-wise model—the univariate fully connected auto-encoder, with the dynamic Gaussian scoring function emerges as a winning candidate for both anomaly detection and diagnosis, beating state-of-the-art algorithms.},
	language = {en},
	number = {6},
	urldate = {2024-08-25},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Garg, Astha and Zhang, Wenyu and Samaran, Jules and Savitha, Ramasamy and Foo, Chuan-Sheng},
	month = jun,
	year = {2022},
	pages = {2508--2517},
}

@article{zhang_unknown_2020,
	title = {Unknown {Attack} {Detection} {Based} on {Zero}-{Shot} {Learning}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9239385/},
	doi = {10.1109/ACCESS.2020.3033494},
	abstract = {In recent years, due to the frequent occurrence of network intrusions, more and more researchers have begun to focus on network intrusion detection. However, it is still a challenge to detect unknown attacks. Currently, there are two main methods of unknown attack detection: clustering and honeypot. But they still have unsolved problems such as difﬁculty in collecting unknown attack samples and failure to detect on time. Zero-Shot learning is proposed to deal with the problem in this article, which can recognize unknown attacks by learning the mapping relations between feature space and semantic space (such as attribute space). When the semantic descriptions of all attacks (including known and unknown attacks) are provided, the classiﬁer built by Zero-Shot learning can extract common semantic information among all attacks and construct connections between known and unknown attacks. The classiﬁer then utilizes the connections to classify unknown attacks although there are no samples for unknown attacks. In this article, we ﬁrst propose to use Zero-Shot learning to overcome the challenge of unknown attack detection and illustrate the feasibility of this method. Secondly, we then propose a novel method of Zero-Shot learning based on sparse autoencoder for unknown attack detection. This method maps the feature of known attacks to the semantic space, and restores the semantic space to the feature space by constrains of reconstruction error, and establishes the feature to semantic mapping, which is used to detect unknown attacks. Veriﬁcation tests have been carried out by using the public dataset NSL\_KDD. From the experiments conducted in this work, the results show that the average accuracy reaches 88.3\%, which performs better than other methods.},
	language = {en},
	urldate = {2024-08-25},
	journal = {IEEE Access},
	author = {Zhang, Zhun and Liu, Qihe and Qiu, Shilin and Zhou, Shijie and Zhang, Cheng},
	year = {2020},
	pages = {193981--193991},
}

@article{niu_lstm-based_2020,
	title = {{LSTM}-{Based} {VAE}-{GAN} for {Time}-{Series} {Anomaly} {Detection}},
	volume = {20},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/13/3738},
	doi = {10.3390/s20133738},
	abstract = {Time series anomaly detection is widely used to monitor the equipment sates through the data collected in the form of time series. At present, the deep learning method based on generative adversarial networks (GAN) has emerged for time series anomaly detection. However, this method needs to ﬁnd the best mapping from real-time space to the latent space at the anomaly detection stage, which brings new errors and takes a long time. In this paper, we propose a long short-term memory-based variational autoencoder generation adversarial networks (LSTM-based VAE-GAN) method for time series anomaly detection, which eﬀectively solves the above problems. Our method jointly trains the encoder, the generator and the discriminator to take advantage of the mapping ability of the encoder and the discrimination ability of the discriminator simultaneously. The long short-term memory (LSTM) networks are used as the encoder, the generator and the discriminator. At the anomaly detection stage, anomalies are detected based on reconstruction diﬀerence and discrimination results. Experimental results show that the proposed method can quickly and accurately detect anomalies.},
	language = {en},
	number = {13},
	urldate = {2024-08-24},
	journal = {Sensors},
	author = {Niu, Zijian and Yu, Ke and Wu, Xiaofei},
	month = jul,
	year = {2020},
	pages = {3738},
}

@article{li_clustering-based_2021,
	title = {Clustering-based anomaly detection in multivariate time series data},
	volume = {100},
	issn = {15684946},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494620308577},
	doi = {10.1016/j.asoc.2020.106919},
	abstract = {Multivariate time series data come as a collection of time series describing different aspects of a certain temporal phenomenon. Anomaly detection in this type of data constitutes a challenging problem yet with numerous applications in science and engineering because anomaly scores come from the simultaneous consideration of the temporal and variable relationships. In this paper, we propose a clustering-based approach to detect anomalies concerning the amplitude and the shape of multivariate time series. First, we use a sliding window to generate a set of multivariate subsequences and thereafter apply an extended fuzzy clustering to reveal a structure present within the generated multivariate subsequences. Finally, a reconstruction criterion is employed to reconstruct the multivariate subsequences with the optimal cluster centers and the partition matrix. We construct a confidence index to quantify a level of anomaly detected in the series and apply Particle Swarm Optimization as an optimization vehicle for the problem of anomaly detection. Experimental studies completed on several synthetic and six real-world datasets suggest that the proposed methods can detect the anomalies in multivariate time series. With the help of available clusters revealed by the extended fuzzy clustering, the proposed framework can detect anomalies in the multivariate time series and is suitable for identifying anomalous amplitude and shape patterns in various application domains such as health care, weather data analysis, finance, and disease outbreak detection.},
	language = {en},
	urldate = {2024-08-24},
	journal = {Applied Soft Computing},
	author = {Li, Jinbo and Izakian, Hesam and Pedrycz, Witold and Jamal, Iqbal},
	month = mar,
	year = {2021},
	pages = {106919},
}

@misc{dau_ucr_2019,
	title = {The {UCR} {Time} {Series} {Archive}},
	url = {http://arxiv.org/abs/1810.07758},
	abstract = {The UCR Time Series Archive - introduced in 2002, has become an important resource in the time series data mining community, with at least one thousand published papers making use of at least one data set from the archive. The original incarnation of the archive had sixteen data sets but since that time, it has gone through periodic expansions. The last expansion took place in the summer of 2015 when the archive grew from 45 to 85 data sets. This paper introduces and will focus on the new data expansion from 85 to 128 data sets. Beyond expanding this valuable resource, this paper offers pragmatic advice to anyone who may wish to evaluate a new algorithm on the archive. Finally, this paper makes a novel and yet actionable claim: of the hundreds of papers that show an improvement over the standard baseline (1-nearest neighbor classiﬁcation), a large fraction may be mis-attributing the reasons for their improvement. Moreover, they may have been able to achieve the same improvement with a much simpler modiﬁcation, requiring just a single line of code.},
	language = {en},
	urldate = {2024-08-23},
	publisher = {arXiv},
	author = {Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
	month = sep,
	year = {2019},
	note = {arXiv:1810.07758 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{kravchik_detecting_2018,
	title = {Detecting {Cyberattacks} in {Industrial} {Control} {Systems} {Using} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1806.08110},
	abstract = {This paper presents a study on detecting cyberattacks on industrial control systems (ICS) using unsupervised deep neural networks, specifically, convolutional neural networks. The study was performed on a Secure Water Treatment testbed (SWaT) dataset, which represents a scaled-down version of a real-world industrial water treatment plant. e suggest a method for anomaly detection based on measuring the statistical deviation of the predicted value from the observed value. We applied the proposed method by using a variety of deep neural networks architectures including different variants of convolutional and recurrent networks. The test dataset from SWaT included 36 different cyberattacks. The proposed method successfully detects the vast majority of the attacks with a low false positive rate thus improving on previous works based on this data set. The results of the study show that 1D convolutional networks can be successfully applied to anomaly detection in industrial control systems and outperform more complex recurrent networks while being much smaller and faster to train.},
	language = {en},
	urldate = {2024-08-21},
	publisher = {arXiv},
	author = {Kravchik, Moshe and Shabtai, Asaf},
	month = dec,
	year = {2018},
	note = {arXiv:1806.08110 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{sabokrou_deep-anomaly__2018,
	title = {Deep-anomaly\_ {Fully} convolutional neural network for fast anomaly detection in crowded scenes},
	abstract = {The detection of abnormal behaviour in crowded scenes has to deal with many challenges. This paper presents an eﬃcient method for detection and localization of anomalies in videos. Using fully convolutional neural networks (FCNs) and temporal data, a pre-trained supervised FCN is transferred into an unsupervised FCN ensuring the detection of (global) anomalies in scenes. High performance in terms of speed and accuracy is achieved by investigating the cascaded detection as a result of reducing computation complexities. This FCN-based architecture addresses two main tasks, feature representation and cascaded outlier detection. Experimental results on two benchmarks suggest that the proposed method outperforms existing methods in terms of accuracy regarding detection and localization.},
	language = {en},
	journal = {Computer Vision and Image Understanding},
	author = {Sabokrou, Mohammad},
	year = {2018},
}

@article{abdulaal_practical_2021,
	title = {Practical {Approach} to {Asynchronous} {Multivariate} {Time} {Series} {Anomaly} {Detection} and {Localization}},
	abstract = {Engineers at eBay utilize robust methods in monitoring IT system signals for anomalies. However, the growing scale of signals, both in volumes and dimensions, overpowers traditional statistical state-space or supervised learning tools. Thus, state-of-the-art methods based on unsupervised deep learning are sought in recent research. However, we experienced flaws when implementing those methods, such as requiring partial supervision and weaknesses to high dimensional datasets, among other reasons discussed in this paper. We propose a practical approach for inferring anomalies from large multivariate sets. We observe an abundance of time series in real-world applications, which exhibit asynchronous and consistent repetitive variations, such as IT, weather, utility, and transportation. Our solution is designed to leverage this behavior. The solution utilizes spectral analysis on the latent representation of a pre-trained autoencoder to extract dominant frequencies across the signals, which are then used in a subsequent network that learns the phase shifts across the signals and produces a synchronized representation of the raw multivariate. Random subsets of the synchronous multivariate are then fed into an array of autoencoders learning to minimize the quantile reconstruction losses, which are then used to infer and localize anomalies based on a majority vote. We benchmark this method against state-of-the-art approaches on public datasets and eBay’s data using their referenced evaluation methods. Furthermore, we address the limitations of the referenced evaluation methods and propose a more realistic evaluation method.},
	language = {en},
	author = {Abdulaal, Ahmed},
	year = {2021},
}

@misc{tuli_tranad_2022,
	title = {{TranAD}: {Deep} {Transformer} {Networks} for {Anomaly} {Detection} in {Multivariate} {Time} {Series} {Data}},
	shorttitle = {{TranAD}},
	url = {http://arxiv.org/abs/2201.07284},
	abstract = {Efficient anomaly detection and diagnosis in multivariate timeseries data is of great importance for modern industrial applications. However, building a system that is able to quickly and accurately pinpoint anomalous observations is a challenging problem. This is due to the lack of anomaly labels, high data volatility and the demands of ultra-low inference times in modern applications. Despite the recent developments of deep learning approaches for anomaly detection, only a few of them can address all of these challenges. In this paper, we propose TranAD, a deep transformer network based anomaly detection and diagnosis model which uses attentionbased sequence encoders to swiftly perform inference with the knowledge of the broader temporal trends in the data. TranAD uses focus score-based self-conditioning to enable robust multi-modal feature extraction and adversarial training to gain stability. Additionally, model-agnostic meta learning (MAML) allows us to train the model using limited data. Extensive empirical studies on six publicly available datasets demonstrate that TranAD can outperform state-of-the-art baseline methods in detection and diagnosis performance with data and time-efficient training. Specifically, TranAD increases F1 scores by up to 17\%, reducing training times by up to 99\% compared to the baselines.},
	language = {en},
	urldate = {2024-08-21},
	publisher = {arXiv},
	author = {Tuli, Shreshth and Casale, Giuliano and Jennings, Nicholas R.},
	month = may,
	year = {2022},
	note = {arXiv:2201.07284 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{he_temporal_2019,
	title = {Temporal {Convolutional} {Networks} for {Anomaly} {Detection} in {Time} {Series}},
	abstract = {Convolutional Networks have been demonstrated to be particularly useful for extracting high level feature in structural data. Temporal convolutional network (TCN) is a framework which employs casual convolutions and dilations so that it is adaptive for sequential data with its temporality and large receptive fields. In this paper, we apply TCN for anomaly detection in time series. We train the TCN on normal sequences and use it to predict trend in a number of time steps. Prediction errors are fitted by a multivariate Gaussian distribution and used to calculate the anomaly scores of points. In addition, a multi-scale feature mixture method is raised to promote performance. The validity of this method is confirmed on three real-world datasets.},
	language = {en},
	journal = {Journal of Physics},
	author = {He, Yangdong and Zhao, Jiabao},
	year = {2019},
}

@article{ye_multivariate_2023,
	title = {Multivariate {Time} {Series} {Anomaly} {Detection} with {Fourier} {Time} {Series} {Transformer}},
	abstract = {Anomaly detection in time series data plays a key role in automatic industrial operations. Due to the intricate temporal dependencies within time series data and the difficulty in obtaining labeled data, recent anomaly detection methods have primarily focused on the temporal domain features of time series data, neglecting the frequency domain features. However, spectral analysis can better utilize periodic information within time series data such as seasonal patterns, which helps capturing multiscale and multiple frequency features. In this paper, we present a Fourier Time Series Transformer model (FTST for short), which combines the features of both time and frequency domains for time series anomaly detection. Specifically, the attention mechanism is utilized for modeling the temporal domain, while the Fourier Transform is employed to transform time series data into frequency domain data. The frequency domain features are then modeled using a Temporal Convolutional Network. By making full use of the temporal and frequency domains of time series data, FTST can significantly enhance the performance of time series anomaly detection. Experimental results on popular benchmark datasets demonstrate the anomaly detection performance of the proposed method.},
	language = {en},
	author = {Ye, Yufeng and He, Qichao and Zhang, Peng and Xiao, Jie and Li, Zhao},
	year = {2023},
}

@article{kitchenham_systematic_2009,
	title = {Systematic literature reviews in software engineering – {A} systematic literature review},
	volume = {51},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09505849},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584908001390},
	doi = {10.1016/j.infsof.2008.09.009},
	abstract = {Background: In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference. Aims: This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence.
Method: We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings.
Results: Of 20 relevant studies, eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4.
Conclusions: Currently, the topic areas covered by SLRs are limited. European researchers, particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence and making it available to practitioners.},
	language = {en},
	number = {1},
	urldate = {2024-08-19},
	journal = {Information and Software Technology},
	author = {Kitchenham, Barbara and Pearl Brereton, O. and Budgen, David and Turner, Mark and Bailey, John and Linkman, Stephen},
	month = jan,
	year = {2009},
	pages = {7--15},
}

@misc{su_large_2024,
	title = {Large {Language} {Models} for {Forecasting} and {Anomaly} {Detection}: {A} {Systematic} {Literature} {Review}},
	shorttitle = {Large {Language} {Models} for {Forecasting} and {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2402.10350},
	abstract = {This systematic literature review comprehensively examines the application of Large Language Models (LLMs) in forecasting and anomaly detection, highlighting the current state of research, inherent challenges, and prospective future directions. LLMs have demonstrated significant potential in parsing and analyzing extensive datasets to identify patterns, predict future events, and detect anomalous behavior across various domains. However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency. Moreover, this review outlines critical trends that are likely to shape the evolution of LLMs in these fields, including the push toward real-time processing, the importance of sustainable modeling practices, and the value of interdisciplinary collaboration. Conclusively, this review underscores the transformative impact LLMs could have on forecasting and anomaly detection while emphasizing the need for continuous innovation, ethical considerations, and practical solutions to realize their full potential.},
	language = {en},
	urldate = {2024-08-19},
	publisher = {arXiv},
	author = {Su, Jing and Jiang, Chufeng and Jin, Xin and Qiao, Yuxin and Xiao, Tingsong and Ma, Hongda and Wei, Rong and Jing, Zhi and Xu, Jiajun and Lin, Junhong},
	month = feb,
	year = {2024},
	note = {arXiv:2402.10350 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{nielsen_neural_2015,
	title = {Neural {Networks} and {Deep} {Learning}},
	language = {en},
	author = {Nielsen, Michael},
	year = {2015},
	pages = {224},
}

@article{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	language = {en},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
}

@misc{yue_ts2vec_2022,
	title = {{TS2Vec}: {Towards} {Universal} {Representation} of {Time} {Series}},
	shorttitle = {{TS2Vec}},
	url = {http://arxiv.org/abs/2106.10466},
	abstract = {This paper presents TS2Vec, a universal framework for learning representations of time series in an arbitrary semantic level. Unlike existing methods, TS2Vec performs contrastive learning in a hierarchical way over augmented context views, which enables a robust contextual representation for each timestamp. Furthermore, to obtain the representation of an arbitrary sub-sequence in the time series, we can apply a simple aggregation over the representations of corresponding timestamps. We conduct extensive experiments on time series classiﬁcation tasks to evaluate the quality of time series representations. As a result, TS2Vec achieves signiﬁcant improvement over existing SOTAs of unsupervised time series representation on 125 UCR datasets and 29 UEA datasets. The learned timestamp-level representations also achieve superior results in time series forecasting and anomaly detection tasks. A linear regression trained on top of the learned representations outperforms previous SOTAs of time series forecasting. Furthermore, we present a simple way to apply the learned representations for unsupervised anomaly detection, which establishes SOTA results in the literature. The source code is publicly available at https://github.com/yuezhihan/ts2vec.},
	language = {en},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Yue, Zhihan and Wang, Yujing and Duan, Juanyong and Yang, Tianmeng and Huang, Congrui and Tong, Yunhai and Xu, Bixiong},
	month = feb,
	year = {2022},
	note = {arXiv:2106.10466 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{li_anomaly_2024,
	title = {Anomaly {Detection} of {Tabular} {Data} {Using} {LLMs}},
	url = {http://arxiv.org/abs/2406.16308},
	abstract = {Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zeroshot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective datagenerating processes to simulate synthetic batchlevel anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Li, Aodong and Zhao, Yunhan and Qiu, Chen and Kloft, Marius and Smyth, Padhraic and Rudolph, Maja and Mandt, Stephan},
	month = jun,
	year = {2024},
	note = {arXiv:2406.16308 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{fung_model_2024,
	title = {Model {Selection} of {Zero}-shot {Anomaly} {Detectors} in the {Absence} of {Labeled} {Validation} {Data}},
	url = {http://arxiv.org/abs/2310.10461},
	abstract = {Anomaly detection requires detecting abnormal samples in large unlabeled datasets. While progress in deep learning and the advent of foundation models has produced powerful zero-shot anomaly detection methods, their deployment in practice is often hindered by the lack of labeled data—without it, their detection performance cannot be evaluated reliably. In this work, we propose SWSA (Selection With Synthetic Anomalies): a general-purpose framework to select image-based anomaly detectors with a generated synthetic validation set. Our proposed anomaly generation method assumes access to only a small support set of normal images and requires no training or finetuning. Once generated, our synthetic validation set is used to create detection tasks that compose a validation framework for model selection. In an empirical study, we find that SWSA often selects models that match selections made with a groundtruth validation set, resulting in higher AUROCs than baseline methods. We also find that SWSA selects prompts for CLIP-based anomaly detection that outperform baseline prompt selection strategies on all datasets, including the challenging MVTec-AD and VisA datasets.},
	language = {en},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Fung, Clement and Qiu, Chen and Li, Aodong and Rudolph, Maja},
	month = feb,
	year = {2024},
	note = {arXiv:2310.10461 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{aota_zero-shot_2023,
	address = {Waikoloa, HI, USA},
	title = {Zero-shot versus {Many}-shot: {Unsupervised} {Texture} {Anomaly} {Detection}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-346-8},
	shorttitle = {Zero-shot versus {Many}-shot},
	url = {https://ieeexplore.ieee.org/document/10030870/},
	doi = {10.1109/WACV56688.2023.00552},
	abstract = {Research on unsupervised anomaly detection (AD) has recently progressed, significantly increasing detection accuracy. This paper focuses on texture images and considers how few normal samples are needed for accurate AD. We first highlight the critical nature of the problem that previous studies have overlooked: accurate detection gets harder for anisotropic textures when image orientations are not aligned between inputs and normal samples. We then propose a zero-shot method, which detects anomalies without using a normal sample. The method is free from the issue of unaligned orientation between input and normal images. It assumes the input texture to be homogeneous, detecting image regions that break the homogeneity as anomalies. We present a quantitative criterion to judge whether this assumption holds for an input texture. Experimental results show the broad applicability of the proposed zero-shot method and its good performance comparable to or even higher than the state-of-the-art methods using hundreds of normal samples. The code and data are available from https://drive.google.com/drive/folders/ 10OyPzvI3H6llCZBxKxFlKWt1Pw1tkMK1.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {2023 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Aota, Toshimichi and Tong, Lloyd Teh Tzer and Okatani, Takayuki},
	month = jan,
	year = {2023},
	pages = {5553--5561},
}

@article{jiao_timeautoad_2022,
	title = {{TimeAutoAD}: {Autonomous} {Anomaly} {Detection} {With} {Self}-{Supervised} {Contrastive} {Loss} for {Multivariate} {Time} {Series}},
	volume = {9},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2327-4697, 2334-329X},
	shorttitle = {{TimeAutoAD}},
	url = {https://ieeexplore.ieee.org/document/9705079/},
	doi = {10.1109/TNSE.2022.3148276},
	abstract = {Multivariate time series (MTS) data are becoming increasingly ubiquitous in networked systems, e.g., IoT systems and 5G networks. Anomaly detection in MTS refers to identifying time series which exhibit different behaviors from normal status. Building such a system, however, is challenging due to a few reasons: i) labels for anomaly cases are usually unavailable or very rare; ii) most existing approaches rely on manual model-design and hyperparameter tuning, which may cost a huge amount of labor effort. To this end, we propose an autonomous anomaly detection technique for multivariate time series data (TimeAutoAD) based on a novel self-supervised contrastive loss. Speciﬁcally, we ﬁrst present an automatic anomaly detection pipeline to optimize the model conﬁguration and hyperparameters automatically. Next, we introduce three different strategies to augment the training data for generating pseudo negative time series and employ a self-supervised contrastive loss to distinguish the original time series and the generated time series. In this way, the representation learning capability of TimeAutoAD can be greatly enhanced and the anomaly detection performance can thus be improved. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoAD not only outperforms state-of-the-art anomaly detection approaches but also exhibits robustness when training data are contaminated.},
	language = {en},
	number = {3},
	urldate = {2024-08-01},
	journal = {IEEE Transactions on Network Science and Engineering},
	author = {Jiao, Yang and Yang, Kai and Song, Dongjing and Tao, Dacheng},
	month = may,
	year = {2022},
	pages = {1604--1619},
}

@inproceedings{lee_time_2023,
	address = {Bali, Indonesia},
	title = {Time {Series} {Anomaly} {Detection} {Using} {Contrastive} {Learning} based {One}-{Class} {Classification}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66545-645-6},
	url = {https://ieeexplore.ieee.org/document/10067089/},
	doi = {10.1109/ICAIIC57133.2023.10067089},
	abstract = {Time series anomaly detection in industrial processes has recently attracted attention. However, since there are no labels in the manufacturing process data collected in real time, there are limitations in using supervised learning-based classification models. Therefore, the proposed method newly defines an objective function that simultaneously learns the OCC model and contrastive learning. In addition, by applying data augmentation techniques suitable for periodic time series data in contrastive learning, feature extraction that preserves temporal characteristics is possible. The effectiveness of representation extraction was verified by showing high anomaly detection performance even in datasets with similar normal and anomaly data forms.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {2023 {International} {Conference} on {Artificial} {Intelligence} in {Information} and {Communication} ({ICAIIC})},
	publisher = {IEEE},
	author = {Lee, Yeseul and Byun, Yunseon and Baek, Jun-Geol},
	month = feb,
	year = {2023},
	pages = {330--335},
}

@article{ngu_cl-tad_2023,
	title = {{CL}-{TAD}: {A} {Contrastive}-{Learning}-{Based} {Method} for {Time} {Series} {Anomaly} {Detection}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	shorttitle = {{CL}-{TAD}},
	url = {https://www.mdpi.com/2076-3417/13/21/11938},
	doi = {10.3390/app132111938},
	abstract = {Anomaly detection has gained increasing attention in recent years, but detecting anomalies in time series data remains challenging due to temporal dynamics, label scarcity, and data diversity in real-world applications. To address these challenges, we introduce a novel method for anomaly detection in time series data, called CL-TAD (Contrastive-Learning-based method for Times series Anomaly Detection), which employs a contrastive-learning-based representation learning technique. Inspired by the successes of reconstruction-based approaches and contrastive learning approaches, the proposed method seeks to leverage these approaches for time series anomaly detection. The CL-TAD method is comprised of two main components: positive sample generation and contrastivelearning-based representation learning. The former component generates positive samples by trying to reconstruct the original data from masked samples. These positive samples, in conjunction with the original data, serve as input for the contrastive-learning-based representation learning component. The representations of input original data and their masked data are used to detect anomalies later on. Experimental results have demonstrated that the CL-TAD method achieved the best performance on ﬁve datasets out of nine benchmark datasets over 10 other recent methods. By leveraging the reconstruction learning and contrastive learning techniques, our method offers a promising solution for effectively detecting anomalies in time series data by handling the issues raised by label scarcity and data diversity, delivering high performance.},
	language = {en},
	number = {21},
	urldate = {2024-08-01},
	journal = {Applied Sciences},
	author = {Ngu, Huynh Cong Viet and Lee, Keon Myung},
	month = oct,
	year = {2023},
	pages = {11938},
}

@inproceedings{su_robust_2019,
	address = {Anchorage AK USA},
	title = {Robust {Anomaly} {Detection} for {Multivariate} {Time} {Series} through {Stochastic} {Recurrent} {Neural} {Network}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330672},
	doi = {10.1145/3292500.3330672},
	abstract = {Industry devices (i.e., entities) such as server machines, spacecrafts, engines, etc., are typically monitored with multivariate time series, whose anomaly detection is critical for an entity’s service quality management. However, due to the complex temporal dependence and stochasticity of multivariate time series, their anomaly detection remains a big challenge. This paper proposes OmniAnomaly, a stochastic recurrent neural network for multivariate time series anomaly detection that works well robustly for various devices. Its core idea is to capture the normal patterns of multivariate time series by learning their robust representations with key techniques such as stochastic variable connection and planar normalizing flow, reconstruct input data by the representations, and use the reconstruction probabilities to determine anomalies. Moreover, for a detected entity anomaly, OmniAnomaly can provide interpretations based on the reconstruction probabilities of its constituent univariate time series. The evaluation experiments are conducted on two public datasets from aerospace and a new server machine dataset (collected and released by us) from an Internet company. OmniAnomaly achieves an overall F1-Score of 0.86 in three real-world datasets, significantly outperforming the best performing baseline method by 0.09. The interpretation accuracy for OmniAnomaly is up to 0.89.},
	language = {en},
	urldate = {2024-08-01},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Su, Ya and Zhao, Youjian and Niu, Chenhao and Liu, Rong and Sun, Wei and Pei, Dan},
	month = jul,
	year = {2019},
	pages = {2828--2837},
}

@misc{pranavan_contrastive_2022,
	title = {Contrastive predictive coding for {Anomaly} {Detection} in {Multi}-variate {Time} {Series} {Data}},
	url = {http://arxiv.org/abs/2202.03639},
	abstract = {Anomaly detection in multi-variate time series (MVTS) data is a huge challenge as it requires simultaneous representation of long term temporal dependencies and correlations across multiple variables. More often, this is solved by breaking the complexity through modeling one dependency at a time. In this paper, we propose a Time-series Representational Learning through Contrastive Predictive Coding (TRL-CPC) towards anomaly detection in MVTS data. First, we jointly optimize an encoder, an auto-regressor and a non-linear transformation function to effectively learn the representations of the MVTS data sets, for predicting future trends. It must be noted that the context vectors are representative of the observation window in the MTVS. Next, the latent representations for the succeeding instants obtained through non-linear transformations of these context vectors, are contrasted with the latent representations of the encoder for the multi-variables such that the density for the positive pair is maximized. Thus, the TRL-CPC helps to model the temporal dependencies and the correlations of the parameters for a healthy signal pattern. Finally, ﬁtting the latent representations are ﬁt into a Gaussian scoring function to detect anomalies. Evaluation of the proposed TRL-CPC on three MVTS data sets against SOTA anomaly detection methods shows the superiority of TRL-CPC.},
	language = {en},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Pranavan, Theivendiram and Sim, Terence and Ambikapathi, Arulmurugan and Ramasamy, Savitha},
	month = feb,
	year = {2022},
	note = {arXiv:2202.03639 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ramirez_rivera_anomaly_2022,
	title = {Anomaly {Detection} {Based} on {Zero}-{Shot} {Outlier} {Synthesis} and {Hierarchical} {Feature} {Distillation}},
	volume = {33},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9228891/},
	doi = {10.1109/TNNLS.2020.3027667},
	abstract = {Anomaly detection suffers from unbalanced data since anomalies are quite rare. Synthetically generated anomalies are a solution to such ill or not fully deﬁned data. However, synthesis requires an expressive representation to guarantee the quality of the generated data. In this article, we propose a two-level hierarchical latent space representation that distills inliers’ feature descriptors [through autoencoders (AEs)] into more robust representations based on a variational family of distributions (through a variational AE) for zero-shot anomaly generation. From the learned latent distributions, we select those that lie on the outskirts of the training data as synthetic-outlier generators. Also, we synthesize from them, i.e., generate negative samples without seen them before, to train binary classiﬁers. We found that the use of the proposed hierarchical structure for feature distillation and fusion creates robust and general representations that allow us to synthesize pseudo outlier samples. Also, in turn, train robust binary classiﬁers for true outlier detection (without the need for actual outliers during training). We demonstrate the performance of our proposal on several benchmarks for anomaly detection.},
	language = {en},
	number = {1},
	urldate = {2024-07-30},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Ramirez Rivera, Adin and Khan, Adil and Bekkouch, Imad Eddine Ibrahim and Sheikh, Taimoor Shakeel},
	month = jan,
	year = {2022},
	pages = {281--291},
}

@misc{jeong_time-series_2022,
	title = {Time-{Series} {Anomaly} {Detection} with {Implicit} {Neural} {Representation}},
	url = {http://arxiv.org/abs/2201.11950},
	abstract = {Detecting anomalies in multivariate time-series data is essential in many real-world applications. Recently, various deep learning-based approaches have shown considerable improvements in timeseries anomaly detection. However, existing methods still have several limitations, such as long training time due to their complex model designs or costly tuning procedures to ﬁnd optimal hyperparameters (e.g., sliding window length) for a given dataset. In our paper, we propose a novel method called Implicit Neural Representationbased Anomaly Detection (INRAD). Speciﬁcally, we train a simple multi-layer perceptron that takes time as input and outputs corresponding values at that time. Then we utilize the representation error as an anomaly score for detecting anomalies. Experiments on ﬁve real-world datasets demonstrate that our proposed method outperforms other state-of-the-art methods in performance, training speed, and robustness.},
	language = {en},
	urldate = {2024-07-30},
	publisher = {arXiv},
	author = {Jeong, Kyeong-Joong and Shin, Yong-Min},
	month = jan,
	year = {2022},
	note = {arXiv:2201.11950 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{beggel_time_2019,
	title = {Time series anomaly detection based on shapelet learning},
	volume = {34},
	issn = {0943-4062, 1613-9658},
	url = {http://link.springer.com/10.1007/s00180-018-0824-9},
	doi = {10.1007/s00180-018-0824-9},
	language = {en},
	number = {3},
	urldate = {2024-07-30},
	journal = {Computational Statistics},
	author = {Beggel, Laura and Kausler, Bernhard X. and Schiegg, Martin and Pfeiffer, Michael and Bischl, Bernd},
	month = sep,
	year = {2019},
	pages = {945--976},
}

@inproceedings{alshaer_detecting_2020,
	address = {Baltimore, MD, USA},
	title = {Detecting {Anomalies} from {Streaming} {Time} {Series} using {Matrix} {Profile} and {Shapelets} {Learning}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72819-228-4},
	url = {https://ieeexplore.ieee.org/document/9288261/},
	doi = {10.1109/ICTAI50040.2020.00066},
	abstract = {Detecting anomalies in streaming time series data with no prior labels is considered a challenging issue, especially, when anomalies may vary with time. There is a need to deal with time series streams by identifying the anomalous patterns. These patterns can be described by representative features extracted from the data, which expresses abnormal behavior. This work addresses the challenge of performing online and continuous learning over time series data. In this paper, a solution based on the Matrix Proﬁle algorithm and representation learning approach is developed. In light of that, we will show how the integration of these widely used approaches in the streaming context is quite important for learning and detecting anomalies in realtime.},
	language = {en},
	urldate = {2024-07-30},
	booktitle = {2020 {IEEE} 32nd {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	publisher = {IEEE},
	author = {Alshaer, Mohammad and Garcia-Rodriguez, Sandra and Gouy-Pailler, Cedric},
	month = nov,
	year = {2020},
	pages = {376--383},
}

@inproceedings{pereira_learning_2019,
	address = {Kyoto, Japan},
	title = {Learning {Representations} from {Healthcare} {Time} {Series} {Data} for {Unsupervised} {Anomaly} {Detection}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-5386-7789-6},
	url = {https://ieeexplore.ieee.org/document/8679157/},
	doi = {10.1109/BIGCOMP.2019.8679157},
	abstract = {The amount of time series data generated in Healthcare is growing very fast and so is the need for methods that can analyse these data, detect anomalies and provide meaningful insights. However, most of the data available is unlabelled and, therefore, anomaly detection in this scenario has been a great challenge for researchers and practitioners.},
	language = {en},
	urldate = {2024-07-30},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} and {Smart} {Computing} ({BigComp})},
	publisher = {IEEE},
	author = {Pereira, Joao and Silveira, Margarida},
	month = feb,
	year = {2019},
	pages = {1--7},
}

@book{gardenfors_conceptual_2000,
	address = {Cambridge, Mass},
	title = {Conceptual spaces: the geometry of thought},
	isbn = {978-0-262-07199-4},
	shorttitle = {Conceptual spaces},
	publisher = {MIT Press},
	author = {Gärdenfors, Peter},
	year = {2000},
	keywords = {Artificial intelligence, Cognitive science},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@misc{ma_survey_2023,
	title = {A {Survey} on {Time}-{Series} {Pre}-{Trained} {Models}},
	url = {http://arxiv.org/abs/2305.10716},
	abstract = {Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difﬁcult due to data annotation costs. Recently, Pre-Trained Models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Speciﬁcally, we ﬁrst brieﬂy introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments are conducted to analyze the advantages and disadvantages of transfer learning strategies, Transformer-based models, and representative TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future work. The source code is available at https://github.com/qianlima-lab/time-series-ptms.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Ma, Qianli and Liu, Zhen and Zheng, Zhenjing and Huang, Ziyang and Zhu, Siying and Yu, Zhongzhong and Kwok, James T.},
	month = may,
	year = {2023},
	note = {arXiv:2305.10716 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{goswami_moment_2024,
	title = {{MOMENT}: {A} {Family} of {Open} {Time}-series {Foundation} {Models}},
	shorttitle = {{MOMENT}},
	url = {http://arxiv.org/abs/2402.03885},
	abstract = {We introduce MOMENT, a family of open-source foundation models for general-purpose time series analysis. Pre-training large models on time series data is challenging due to (1) the absence of a large and cohesive public time series repository, and (2) diverse time series characteristics which make multi-dataset training onerous. Additionally, (3) experimental benchmarks to evaluate these models, especially in scenarios with limited resources, time, and supervision, are still in their nascent stages. To address these challenges, we compile a large and diverse collection of public time series, called the Time series Pile, and systematically tackle time series-specific challenges to unlock large-scale multi-dataset pretraining. Finally, we build on recent work to design a benchmark to evaluate time series foundation models on diverse tasks and datasets in limited supervision settings. Experiments on this benchmark demonstrate the effectiveness of our pre-trained models with minimal data and taskspecific fine-tuning. Finally, we present several interesting empirical observations about large pretrained time series models. Pre-trained models (AutonLab/MOMENT-1-large) and Time Series Pile (AutonLab/Timeseries-PILE) are available on https://huggingface.co/AutonLab.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Goswami, Mononito and Szafer, Konrad and Choudhry, Arjun and Cai, Yifu and Li, Shuo and Dubrawski, Artur},
	month = may,
	year = {2024},
	note = {arXiv:2402.03885 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{xu_anomaly_2022,
	title = {Anomaly {Transformer}: {Time} {Series} {Anomaly} {Detection} with {Association} {Discrepancy}},
	shorttitle = {Anomaly {Transformer}},
	url = {http://arxiv.org/abs/2110.02642},
	abstract = {Unsupervised detection of anomaly points in time series is a challenging problem, which requires the model to derive a distinguishable criterion. Previous methods tackle the problem mainly through learning pointwise representation or pairwise association, however, neither is sufﬁcient to reason about the intricate dynamics. Recently, Transformers have shown great power in uniﬁed modeling of pointwise representation and pairwise association, and we ﬁnd that the self-attention weight distribution of each time point can embody rich association with the whole series. Our key observation is that due to the rarity of anomalies, it is extremely difﬁcult to build nontrivial associations from abnormal points to the whole series, thereby, the anomalies’ associations shall mainly concentrate on their adjacent time points. This adjacent-concentration bias implies an association-based criterion inherently distinguishable between normal and abnormal points, which we highlight through the Association Discrepancy. Technically, we propose the Anomaly Transformer with a new Anomaly-Attention mechanism to compute the association discrepancy. A minimax strategy is devised to amplify the normal-abnormal distinguishability of the association discrepancy. The Anomaly Transformer achieves state-of-theart results on six unsupervised time series anomaly detection benchmarks of three applications: service monitoring, space \& earth exploration, and water treatment.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Xu, Jiehui and Wu, Haixu and Wang, Jianmin and Long, Mingsheng},
	month = jun,
	year = {2022},
	note = {arXiv:2110.02642 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{darban_carla_2024,
	title = {{CARLA}: {Self}-supervised {Contrastive} {Representation} {Learning} for {Time} {Series} {Anomaly} {Detection}},
	shorttitle = {{CARLA}},
	url = {http://arxiv.org/abs/2308.09296},
	abstract = {One main challenge in time series anomaly detection (TSAD) is the lack of labelled data in many real-life scenarios. Most of the existing anomaly detection methods focus on learning the normal behaviour of unlabelled time series in an unsupervised manner. The normal boundary is often defined tightly, resulting in slight deviations being classified as anomalies, consequently leading to a high false positive rate and a limited ability to generalise normal patterns. To address this, we introduce a novel end-to-end self-supervised ContrAstive Representation Learning approach for time series Anomaly detection (CARLA). While existing contrastive learning methods assume that augmented time series windows are positive samples and temporally distant windows are negative samples, we argue that these assumptions are limited as augmentation of time series can transform them to negative samples, and a temporally distant window can represent a positive sample. Our contrastive approach leverages existing generic knowledge about time series anomalies and injects various types of anomalies as negative samples. Therefore, CARLA not only learns normal behaviour but also learns deviations indicating anomalies. It creates similar representations for temporally closed windows and distinct ones for anomalies. Additionally, it leverages the information about representations' neighbours through a self-supervised approach to classify windows based on their nearest/furthest neighbours to further enhance the performance of anomaly detection. In extensive tests on seven major real-world time series anomaly detection datasets, CARLA shows superior performance over state-of-the-art self-supervised and unsupervised TSAD methods. Our research shows the potential of contrastive representation learning to advance time series anomaly detection.},
	language = {en},
	urldate = {2024-07-18},
	publisher = {arXiv},
	author = {Darban, Zahra Zamanzadeh and Webb, Geoffrey I. and Pan, Shirui and Aggarwal, Charu C. and Salehi, Mahsa},
	month = apr,
	year = {2024},
	note = {arXiv:2308.09296 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{gruhl_novelty_2022,
	title = {Novelty {Detection} for {Multivariate} {Data} {Streams} with {Probalistic} {Models}},
	copyright = {Creative Commons Attribution Share Alike 4.0 International, open access},
	url = {https://kobra.uni-kassel.de/handle/123456789/13902},
	doi = {10.17170/KOBRA-202205106160},
	language = {en},
	urldate = {2024-07-15},
	author = {Gruhl, Christian M.},
	collaborator = {{Universität Kassel}},
	year = {2022},
	note = {Publisher: Universität Kassel},
	keywords = {620, Anomalieerkennung, Autonomer Agent, Daten, Datenstrom, Maschinelles Lernen, Sensor, Wahrscheinlichkeitsmaß, anomalies, anomaly detection, concept drift, data streams, machine learning, novelties, novelty detection, outliers, probabilistic modeling},
}

@inproceedings{gangloff_unsupervised_2023,
	address = {Kuala Lumpur, Malaysia},
	title = {Unsupervised {Anomaly} {Detection} {Using} {Variational} {Autoencoder} with {Gaussian} {Random} {Field} {Prior}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-72819-835-4},
	url = {https://ieeexplore.ieee.org/document/10222900/},
	doi = {10.1109/ICIP49359.2023.10222900},
	abstract = {We propose a new model of Variational Autoencoder (VAE) for Anomaly Detection (AD) with improved modeling power. More precisely, we introduce a VAE model with a Gaussian Random Field (GRF) prior, namely VAE-GRF, which generalizes the classical VAE model. We show that, under some assumptions, the VAE-GRF largely outperforms the traditional VAE and some other probabilistic models developed for AD. Our experimental results suggest that the VAE-GRF could be used as a relevant VAE baseline in place of the traditional VAE with very limited additional computational cost. We provide competitive results on the public MVTec benchmark dataset for visual inspection, as well as on the public Livestock dataset dedicated to the task of unsupervised animal detection from aerial images.},
	language = {en},
	urldate = {2024-07-15},
	booktitle = {2023 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Gangloff, Hugo and Pham, Minh-Tan and Courtrai, Luc and Lefèvre, Sébastien},
	month = oct,
	year = {2023},
	pages = {1620--1624},
}

@inproceedings{gangloff_leveraging_2022,
	address = {Montreal, QC, Canada},
	title = {Leveraging {Vector}-{Quantized} {Variational} {Autoencoder} {Inner} {Metrics} for {Anomaly} {Detection}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-062-7},
	url = {https://ieeexplore.ieee.org/document/9956102/},
	doi = {10.1109/ICPR56361.2022.9956102},
	abstract = {Anomaly Detection (AD) is an important research topic, with very diverse applications such as industrial defect detection, medical diagnosis, fraud detection, intrusion detection, etc. Within the last few years, deep learning-based methods have become the standard approach for AD. In many practical cases, the anomalies are unknown in advance. Therefore, most of challenging AD problems need to be addressed in an unsupervised or weakly supervised framework. In this context, deep generative models are widely used, in particular Variational Autoencoder (VAE) models. VAEs have been extended to Vector-Quantized VAEs (VQ-VAEs), a model increasingly popular because of its versatility enabled by the discrete latent space. We present for the first time a robust approach which takes advantage of the inner metrics of VQ-VAEs for AD. We show that the distance between the output of the encoder and the codebook vectors of a VQ-VAE provides a valuable information which can be used to localize the anomalies. In our approach, this metric complements a reconstruction-based metric to improve AD results. We compare our model with state-of-the-art AD models on three standards datasets, including the MVTec, UCSD-Ped1 and CIFAR-10 datasets. Experiments show that the proposed method yields high competitive results.},
	language = {en},
	urldate = {2024-07-15},
	booktitle = {2022 26th {International} {Conference} on {Pattern} {Recognition} ({ICPR})},
	publisher = {IEEE},
	author = {Gangloff, Hugo and Pham, Minh-Tan and Courtrai, Luc and Lefevre, Sebastien},
	month = aug,
	year = {2022},
	pages = {435--441},
}

@article{palatucci_zero-shot_2009,
	title = {Zero-shot {Learning} with {Semantic} {Output} {Codes}},
	abstract = {We consider the problem of zero-shot learning, where the goal is to learn a classiﬁer f : X → Y that must predict novel values of Y that were omitted from the training set. To achieve this, we deﬁne the notion of a semantic output code classiﬁer (SOC) which utilizes a knowledge base of semantic properties of Y to extrapolate to novel classes. We provide a formalism for this type of classiﬁer and study its theoretical properties in a PAC framework, showing conditions under which the classiﬁer can accurately predict novel classes. As a case study, we build a SOC classiﬁer for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images (fMRI) of their neural activity, even without training examples for those words.},
	language = {en},
	author = {Palatucci, Mark and Pomerleau, Dean and Hinton, Geoffrey E and Mitchell, Tom M},
	year = {2009},
}

@misc{socher_zero-shot_2013,
	title = {Zero-{Shot} {Learning} {Through} {Cross}-{Modal} {Transfer}},
	url = {http://arxiv.org/abs/1301.3666},
	abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the objects. The only necessary knowledge about the unseen categories comes from unsupervised large text corpora. In our zero-shot framework distributional information in language can be seen as spanning a semantic basis for understanding what objects look like. Most previous zero-shot learning models can only differentiate between unseen classes. In contrast, our model can both obtain state of the art performance on classes that have thousands of training images and obtain reasonable performance on unseen classes. This is achieved by ﬁrst using outlier detection in the semantic space and then two separate recognition models. Furthermore, our model does not require any manually deﬁned semantic features for either words or images.},
	language = {en},
	urldate = {2024-07-14},
	publisher = {arXiv},
	author = {Socher, Richard and Ganjoo, Milind and Sridhar, Hamsa and Bastani, Osbert and Manning, Christopher D. and Ng, Andrew Y.},
	month = mar,
	year = {2013},
	note = {arXiv:1301.3666 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Machine learning},
}

@article{sun_survey_2021,
	title = {A {Survey} on {Deep} {Learning} for {Data}-{Driven} {Soft} {Sensors}},
	volume = {17},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1551-3203, 1941-0050},
	url = {https://ieeexplore.ieee.org/document/9329169/},
	doi = {10.1109/TII.2021.3053128},
	abstract = {Soft sensors are widely constructed in process industry to realize process monitoring, quality prediction, and many other important applications. With the development of hardware and software, industrial processes have embraced new characteristics, which lead to the poor performance of traditional soft sensor modeling methods. Deep learning, as a kind of data-driven approach, shows its great potential in many ﬁelds, as well as in soft sensing scenarios. After a period of development, especially in the last ﬁve years, many new issues have emerged that need to be investigated. Therefore, in this article, the necessity and signiﬁcance of deep learning for soft sensor applications are demonstrated ﬁrst by analyzing the merits of deep learning and the trends of industrial processes. Next, mainstream deep learning models, tricks, and frameworks/toolkits are summarized and discussed to help designers propel the developing progress of soft sensors. Then, existing works are reviewed and analyzed to discuss the demands and problems occurred in practical applications. Finally, outlook and conclusions are given.},
	language = {en},
	number = {9},
	urldate = {2024-07-14},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Sun, Qingqiang and Ge, Zhiqiang},
	month = sep,
	year = {2021},
	pages = {5853--5866},
}
