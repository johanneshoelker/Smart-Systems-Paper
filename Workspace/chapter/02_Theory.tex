\chapter{Definitions and Conventions}\label{theory}
\section{Representation Learning}
Representation Learning mainly tries to detect interconnections in data, which represent meanings relevant for further data analysis. There are several representation learning techniques to detect patterns and to store them in different ways.\\
\cite{lavrac_representation_2021} 1.3
divides techniques into Propositionalization and Embeddings.\\
Propositionalization:
Embeddings:\\
Representations in data
In the book of \citeA{goodfellow_deep_2016} this general detailed description of representation learning is given. They sum up that a representations should make the subsequent learning tasks easier. This implicates that to find a the best fitting representation and the underlying representation learning technique, we need to know the task it should perform afterwards.
\subsection{Evaluation}
% \cite{lavric} 1.4.1
This chapter describes how to evaluate the performance of an RL approach.\\
\cite{bengio_representation_2013} describes what makes a representation "good". They list the following factors:\\
\begin{itemize}
  \item Smoothness
  \item Multiple Explanatory Factors
  \item A hierarchical organization of explanatory factors
  \item Sparsity
\end{itemize}
We want to find properties of the data but at the same time we don't want to loose information about the input \cite[S. 525]{goodfellow_deep_2016}\\

\section{Zero Shot Learning}
Zero Shot Learning is an extreme form of transfer learning \cite[S. 536]{goodfellow_deep_2016}. While transfer learning is the concept of transferring the knowledge and weights gained at one task using them at solving another task, Zero-Shot Learning means there are no samples for the other task. The transformation of knowledge can help solving tasks where there are few or no samples available. The gained knowledge is normally stored as representations in the data. Representations which are abstract enough to not see a specific item but information about items which can be applicated to groups of items. THis also means that Zero-Shot Learning is only possible because addition information has been discovered during training.\\
\cite{palatucci_zero-shot_2009} were the first to implement a successful Zero-Shot Detection followed by \cite{socher_zero-shot_2013} who used semantic word vector representations to classify words in groups and to sort new words with an accuracy of 90\% with a fully unsupervised mdoel.
\section{Anomaly Detection}
detailed description
% TODO
% ## Theoretischer Rahmen
% Definitionen und Konzepte: Detaillierte Erklärungen zu Representation Learning, Zero Shot Learning und Anomaly Detection.
% Methoden und Techniken: Überblick über die verschiedenen Ansätze und Methoden im Representation Learning (z.B. Autoencoder, CNNs, Word Embeddings).
