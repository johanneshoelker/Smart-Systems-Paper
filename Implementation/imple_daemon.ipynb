{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T13:44:22.187446Z",
     "start_time": "2024-09-20T13:44:11.432108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from smadata import getSMAData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_SMA(xtrain_dfs, xtest_dfs, ytrain_dfs, ytest_dfs):\n",
    "    # Combine all the training and testing data for normalization\n",
    "    all_train_data = pd.concat(xtrain_dfs.values())\n",
    "    all_test_data = pd.concat(xtest_dfs.values())\n",
    "\n",
    "    # Normalize the data using the combined dataset mean and std\n",
    "    mean = np.nanmean(all_train_data)\n",
    "    std = np.nanstd(all_train_data)\n",
    "\n",
    "    # Preprocess each inverter's data\n",
    "    train_data_list = []\n",
    "    train_labels_list = []\n",
    "    test_data_list = []\n",
    "    test_labels_list = []\n",
    "\n",
    "    for inv in xtrain_dfs.keys():\n",
    "        xtrain = xtrain_dfs[inv].values.astype(np.float64)\n",
    "        xtest = xtest_dfs[inv].values.astype(np.float64)\n",
    "        ytrain = ytrain_dfs[inv].values.flatten()\n",
    "        ytest = ytest_dfs[inv].values.flatten()\n",
    "\n",
    "        # Normalize the data\n",
    "        xtrain = (xtrain - mean) / std\n",
    "        xtest = (xtest - mean) / std\n",
    "\n",
    "        # Reshape the data to add a new axis\n",
    "        train_data_list.append(xtrain[..., np.newaxis])\n",
    "        train_labels_list.append(ytrain)\n",
    "        test_data_list.append(xtest[..., np.newaxis])\n",
    "        test_labels_list.append(ytest)\n",
    "\n",
    "    # Concatenate all inverter data into single arrays\n",
    "    train_data = np.concatenate(train_data_list, axis=0)\n",
    "    train_labels = np.concatenate(train_labels_list, axis=0)\n",
    "    test_data = np.concatenate(test_data_list, axis=0)\n",
    "    test_labels = np.concatenate(test_labels_list, axis=0)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "# Usage\n",
    "xtrain_dfs, xtest_dfs, ytrain_dfs, ytest_dfs = getSMAData()\n",
    "train_data, train_labels, test_data, test_labels = preprocess_SMA(xtrain_dfs, xtest_dfs, ytrain_dfs, ytest_dfs)\n"
   ],
   "id": "6bceaf35539a0333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6057, 137) (11645, 137)\n",
      "(6062, 137) (11231, 137)\n",
      "(6180, 137) (11258, 137)\n",
      "(5490, 137) (11139, 137)\n",
      "(5516, 137) (10925, 137)\n",
      "(5980, 137) (12281, 137)\n",
      "(5923, 137) (10865, 137)\n",
      "(6180, 137) (12319, 137)\n",
      "(6180, 137) (8601, 137)\n",
      "(6180, 137) (12146, 137)\n",
      "(6165, 137) (11853, 137)\n",
      "(6176, 137) (11752, 137)\n",
      "(5741, 137) (12236, 137)\n",
      "(6180, 137) (12122, 137)\n",
      "(6159, 137) (12339, 137)\n",
      "(6162, 137) (12333, 137)\n",
      "(6180, 137) (12340, 137)\n",
      "(6180, 137) (12339, 137)\n",
      "(6180, 137) (12310, 137)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T13:44:48.180219Z",
     "start_time": "2024-09-20T13:44:46.812914Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from daemon.model import DAEMON\n",
    "\n",
    "# Assuming train_data, train_labels, test_data, test_labels have been preprocessed\n",
    "def create_dataloader(data, labels, batch_size=32):\n",
    "    # Create a TensorDataset and DataLoader\n",
    "    dataset = TensorDataset(torch.FloatTensor(data), torch.FloatTensor(labels))\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Prepare the data\n",
    "train_dataloader = create_dataloader(train_data, train_labels)\n",
    "test_dataloader = create_dataloader(test_data, test_labels)\n",
    "\n",
    "# Define model options\n",
    "class Opt:\n",
    "    ngpu = 1\n",
    "    ndf = 64  # Example value\n",
    "    nz = 32   # Example value\n",
    "    lr_d = 0.0002\n",
    "    lr_g = 0.0002\n",
    "    beta1 = 0.5\n",
    "    train_batchsize = 32\n",
    "    val_batchsize = 32\n",
    "    test_batchsize = 32\n",
    "    niter = 100  # Adjust as needed\n",
    "    patience = 10\n",
    "    w_rec = 1\n",
    "    w_lat = 1\n",
    "    print_freq = 10\n",
    "\n",
    "opt = Opt()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the DAEMON model\n",
    "daemon_model = DAEMON(opt, train_dataloader, None, test_data, test_labels, device)\n",
    "\n",
    "# Forward pass through the model\n",
    "def forward_pass(model, dataloader):\n",
    "    model.G.eval()  # Set the model to evaluation mode\n",
    "    all_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            data = data.permute([0, 2, 1]).to(device)  # Reshape as needed\n",
    "            outputs, _, _, _ = model.G(data)  # Forward pass\n",
    "            all_outputs.append(outputs.cpu().numpy())  # Store outputs\n",
    "\n",
    "    return np.concatenate(all_outputs, axis=0)\n",
    "\n",
    "# Perform the forward pass on the test data\n",
    "outputs = forward_pass(daemon_model, test_dataloader)\n",
    "\n",
    "# outputs now contains the results from the generator model\n",
    "print(\"Outputs from the DAEMON model:\", outputs)\n"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Opt' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Initialize the DAEMON model\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m daemon_model \u001B[38;5;241m=\u001B[39m \u001B[43mDAEMON\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Forward pass through the model\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_pass\u001B[39m(model, dataloader):\n",
      "File \u001B[1;32mD:\\workspaces\\anomaly-detection\\DAEMON\\daemon\\model.py:98\u001B[0m, in \u001B[0;36mDAEMON.__init__\u001B[1;34m(self, opt, train_dataloader, val_dataloader, test_data, label, device)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, opt, train_dataloader, val_dataloader, test_data, label, device):\n\u001B[1;32m---> 98\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDAEMON\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mearly_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(opt, patience\u001B[38;5;241m=\u001B[39mopt\u001B[38;5;241m.\u001B[39mpatience, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt \u001B[38;5;241m=\u001B[39m opt\n",
      "File \u001B[1;32mD:\\workspaces\\anomaly-detection\\DAEMON\\daemon\\network.py:119\u001B[0m, in \u001B[0;36mDAEMON_MODEL.__init__\u001B[1;34m(self, opt)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopt \u001B[38;5;241m=\u001B[39m opt\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mniter \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39mniter\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m \u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutf \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39moutf\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Opt' object has no attribute 'dataset'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "512ec396c5efb128"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
